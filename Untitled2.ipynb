{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e54522b-41e5-4f29-bd26-03b5a7784ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import faiss\n",
    "import sentencepiece as spm\n",
    "import fitz  # PyMuPDF\n",
    "from decoder_only_gpt import My_GPT_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e0303fc-4b9e-422c-9a78-cc261e99abd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"hindi_tokenizer_new.model\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d38196cc-43c2-40df-a582-24a058bbb26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41cb8a35-bcc4-462b-a68f-8ac0260e42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = My_GPT_model(vocab_size=sp.get_piece_size(), num_layers=12,\n",
    "    d_model=512, d_ff=2048, num_heads=8,seq_len=512\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d3735f2-fe2c-4831-818d-7b5363143906",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"checkpoints_HindiGPT-v1_step280000.pt\", map_location=DEVICE)\n",
    "state_dict = ckpt[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9a0347f-e257-4b20-929b-7ea54e435c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f92e8a8c-35d9-4425-9e33-5337800ae9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My_GPT_model(\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(32768, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Decoder_GPT_Block(\n",
       "        (swi_glu): SwiGLU_FFN(\n",
       "          (w1): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (w2): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (w3): Linear(in_features=1536, out_features=512, bias=False)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (masked_mha): Masked_MHA(\n",
       "          (Q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (K): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (V): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (rms_norm0): RMSNorm()\n",
       "        (rms_norm1): RMSNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(clean_state_dict, strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025bba7d-5b1b-4107-a4db-a87b6972daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embed_model = SentenceTransformer(\n",
    "    \"intfloat/multilingual-e5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a1e060-673e-4483-bd69-0035f7eea173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "reranker = CrossEncoder(\"cross-encoder/mmarco-mMiniLMv2-L12-H384-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bc345d8-ea5a-42ee-b4eb-5a27434da02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hindi_text(text):\n",
    "    text = re.sub(r\"[⁇�]\", \"\", text)  # OCR garbage\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Extra spaces\n",
    "    text = text.replace(\" ो\", \"ो\").replace(\" ै\", \"ै\").replace(\" ी\", \"ी\").replace(\" ु\", \"ु\").replace(\" ू\", \"ू\")\n",
    "    text = re.sub(r\"[^\\u0900-\\u097F\\u0041-\\u005A\\u0061-\\u007A।\\s0-9]\", \" \", text)  # Keep English/numbers if mixed\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "62cb371a-56a8-4194-ac9f-fe5d9962dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_chunk_hindi(text, max_tokens=200, overlap=2):\n",
    "    sentences = re.split(r\"(।|\\n)\", text)\n",
    "    sentences = [\"\".join(sentences[i:i+2]) for i in range(0, len(sentences), 2)]\n",
    "    chunks = []\n",
    "    current = []\n",
    "    for sent in sentences:\n",
    "        current.append(sent)\n",
    "        token_len = len(sp.encode(\" \".join(current)))\n",
    "        if token_len >= max_tokens:\n",
    "            chunks.append(\" \".join(current))\n",
    "            current = current[-overlap:]\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2399333-740b-4a39-b51a-a7230bda634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_faiss_index(chunks):\n",
    "    embeddings = embed_model.encode(\n",
    "        [\"passage: \" + t for t in chunks],\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(embeddings)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4985917b-df25-475b-ad06-824a6d0126c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query, chunks, index, top_k=10, rerank_top=3, min_score=0.5):\n",
    "    query_emb = embed_model.encode([\"query: \" + query], normalize_embeddings=True)\n",
    "    scores, idxs = index.search(query_emb, top_k)\n",
    "    candidate_texts = []\n",
    "    for i, score in zip(idxs[0], scores[0]):\n",
    "        if score < min_score:\n",
    "            continue\n",
    "        candidate_texts.append(chunks[i])\n",
    "    \n",
    "    if not candidate_texts:\n",
    "        return []\n",
    "    \n",
    "    # Rerank top candidates\n",
    "    reranked = rerank(query, candidate_texts, top_k=rerank_top)\n",
    "    context_ids = []\n",
    "    for t in reranked:\n",
    "        context_ids += sp.encode(f\"\\n[संदर्भ]\\n{t}\\n\")\n",
    "    \n",
    "    # Limit context to ~400 tokens to fit model\n",
    "    return context_ids[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1ed48ec-40ce-4013-8af5-2a2a245ee223",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(query, candidate_texts, top_k=3):\n",
    "    pairs = [(query, t) for t in candidate_texts]\n",
    "    scores = reranker.predict(pairs)\n",
    "    ranked = sorted(zip(candidate_texts, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [x[0] for x in ranked[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd16ae9b-36c0-46ab-b599-b33da8e54975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_prompt_ids ko simple bana\n",
    "def build_prompt_ids(context_ids, question):\n",
    "    instruction = \"संदर्भ के आधार पर हिंदी में सटीक उत्तर दो।\"\n",
    "    prompt_ids = (\n",
    "        sp.encode(instruction + \"\\n\\nसंदर्भ:\\n\") +\n",
    "        context_ids[:250] +  # Hard limit 250 tokens context\n",
    "        sp.encode(\"\\nप्रश्न: \" + question + \"\\nउत्तर:\\n\")\n",
    "    )\n",
    "    return prompt_ids  # No BOS if causing issues, ya sp.bos_id() last mein try\n",
    "\n",
    "# Generate settings\n",
    "answer = generate_answer_from_ids(\n",
    "    prompt_ids,\n",
    "    max_new_tokens=250,\n",
    "    temperature=0.9,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "456915a6-5b69-4da5-a11f-cf6539b9be20",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_ID = sp.eos_id()\n",
    "@torch.no_grad()\n",
    "def generate_answer_from_ids(prompt_ids, max_new_tokens=300, temperature=0.7, top_p=0.95, repetition_penalty=1.2):\n",
    "    input_ids = torch.tensor([prompt_ids], dtype=torch.long).to(DEVICE)\n",
    "    generated = input_ids.clone()  # copy for tracking\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        if generated.shape[1] >= 512:\n",
    "            generated = generated[:, -512:]\n",
    "            \n",
    "        logits = model(generated)\n",
    "        next_logits = logits[:, -1, :]\n",
    "        \n",
    "        # Repetition penalty\n",
    "        if repetition_penalty > 1.0:\n",
    "            recent = generated[0, -128:].tolist()\n",
    "            for tid in set(recent):\n",
    "                next_logits[0, tid] /= repetition_penalty\n",
    "        \n",
    "        # Temperature + top-p\n",
    "        next_logits = next_logits / temperature\n",
    "        probs = torch.softmax(next_logits, dim=-1)\n",
    "        \n",
    "        # Nucleus sampling\n",
    "        sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
    "        cum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        mask = cum_probs > top_p\n",
    "        mask[..., 1:] = mask[..., :-1].clone()\n",
    "        mask[..., 0] = False\n",
    "        sorted_probs[mask] = 0.0\n",
    "        if sorted_probs.sum() > 0:\n",
    "            sorted_probs /= sorted_probs.sum()\n",
    "        \n",
    "        next_token = torch.multinomial(sorted_probs, num_samples=1)\n",
    "        next_token = sorted_idx.gather(-1, next_token)\n",
    "        \n",
    "        generated = torch.cat([generated, next_token], dim=1)\n",
    "        \n",
    "        if next_token.item() == sp.eos_id():\n",
    "            break\n",
    "    \n",
    "    # Sirf NEW generated tokens decode karo (prompt ke baad se)\n",
    "    prompt_len = len(prompt_ids)\n",
    "    answer_ids = generated[0, prompt_len:].tolist()\n",
    "    return sp.decode(answer_ids).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8cae929f-98ae-4aa9-ab65-c53b4597b231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29203289dc714053b73e497080d6087f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "्रद्विजपन्ति-वादिताके अलावा,वक्त-सामयिक विषयोंकी चर्चा करेंगे। गांधीजीके जन्मस्थान को अपने घर में ही स्थापित करने एवं राष्ट्र निर्माणमें उनका महत्वपूर्ण योगदान होनेकेलिएआज भी बापूजी की वह प्रतिमा है जिसको वे कभी नहीं रोक सकते थे। इसी प्रकार,अहिंसा से मुक्त होकर,एक स्वतंत्र राष्ट्र के निर्माणके लिए उन्होंनेअपने विचारों का प्रसार किया। उन्होंने मध्य प्रदेश में भ्रमण कर लोगोंसे मुलाकात की और उन्हें भारत-पाक संबंधो पर जानकारी दी।\n"
     ]
    }
   ],
   "source": [
    "def rag_pipeline(pdf_path, question):\n",
    "    # Load and clean PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    pdf_text = clean_hindi_text(text)\n",
    "    \n",
    "    # Chunk\n",
    "    chunks = sentence_chunk_hindi(pdf_text)\n",
    "    \n",
    "    # Build index\n",
    "    index = build_faiss_index(chunks)\n",
    "    \n",
    "    # Retrieve\n",
    "    context_ids = retrieve_context(question, chunks, index)\n",
    "    \n",
    "    if not context_ids:\n",
    "        return \"संदर्भ में संबंधित जानकारी उपलब्ध नहीं है।\"\n",
    "    \n",
    "    # Build prompt\n",
    "    prompt_ids = build_prompt_ids(context_ids, question)\n",
    "    \n",
    "    # Generate\n",
    "    answer = generate_answer_from_ids(prompt_ids)\n",
    "    answer = post_process_hindi(answer)\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"gandhi.pdf\"  # Tu apni PDF daal, jaise Mahatma Gandhi bio ya koi short story\n",
    "question = \"गांधीजी की मुख्य विचारधारा क्या थी? अहिंसा और सत्य के बारे में बताइए।\"  # Ya koi simple question PDF ke hisaab se\n",
    "\n",
    "answer = rag_pipeline(pdf_path, question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c9990dc-a59f-430c-9edf-3cf416ca8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_hindi(text):\n",
    "    # Extra spaces remove\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Punctuation ke baad space (agar nahi hai toh daal do)\n",
    "    text = re.sub(r'([।?!])([^\\s])', r'\\1 \\2', text)\n",
    "    # Sentence end pe proper space\n",
    "    text = text.replace(\"।\", \"। \")\n",
    "    # Multiple spaces after । ko single kar\n",
    "    text = re.sub(r'।\\s+', '। ', text)\n",
    "    # Starting aur ending spaces hatao\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "06ec6ee8-5ca1-49a5-8609-2bcf8c824836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7827623601440b38ee82ba9e4eb662e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 291\n",
      "Decoded prompt start: संदर्भ के आधार पर हिंदी में सटीक उत्तर दो। ⁇ संदर्भ: ⁇   ⁇ संदर्भ ⁇  अस्पृश्यता केखि लाफसंघर्ष गांधीजी नेहरिजनों दलितों केउत्थानकेलिएबहुतकामकिया। उन्होंने हरिजन शब्दगढ़ा औरमंदिरप्रवेश पानी केस्रोतों परअधिकारजैसेआंदोलनचलाए। पूना पैक्ट 1932 केमाध्यमसेउन्होंनेदलितों केलिएअलगनिर्वाचन क्षेत्रकी मांगरोकी। विचारधारा गांधीजी की मुख्यविचारधारा\n"
     ]
    }
   ],
   "source": [
    "doc = fitz.open(pdf_path)\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text += page.get_text()\n",
    "pdf_text = clean_hindi_text(text)\n",
    "pdf_text = post_process_hindi(pdf_text)\n",
    "\n",
    "# Chunk\n",
    "chunks = sentence_chunk_hindi(pdf_text)\n",
    "    \n",
    "# Build index\n",
    "index = build_faiss_index(chunks)\n",
    "\n",
    "# Retrieve\n",
    "context_ids = retrieve_context(question, chunks, index)\n",
    "\n",
    "prompt_ids = build_prompt_ids(context_ids, question)\n",
    "print(\"Prompt length:\", len(prompt_ids))\n",
    "print(\"Decoded prompt start:\", sp.decode(prompt_ids[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "69c31c39-1e7b-4b4d-9e9f-a3b77824758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: न्दर्भः- ।\n"
     ]
    }
   ],
   "source": [
    "question = \"महात्मा गांधी का जन्म कब हुआ?\"\n",
    "dummy_context = sp.encode(\"महात्मा गांधी का जन्म 2 अक्टूबर 1869 को पोरबंदर में हुआ था।\")\n",
    "prompt_ids = build_prompt_ids(dummy_context, question)\n",
    "answer = generate_answer_from_ids(prompt_ids)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55561b1f-f6c6-43a8-9ba1-1397d29a8499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
