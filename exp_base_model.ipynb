{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6034488f-a00c-4cb0-b690-43d530d06d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a73dfc4-162b-417d-98d4-d05b8f00ebee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file=\"hindi_tokenizer_new.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b02244d-392d-4785-975c-3298d6cda8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32768\n",
      "PAD: 0\n",
      "BOS: 2\n",
      "EOS: 3\n",
      "UNK: 1\n"
     ]
    }
   ],
   "source": [
    "print(sp.get_piece_size())\n",
    "\n",
    "print(\"PAD:\", sp.pad_id())\n",
    "print(\"BOS:\", sp.bos_id())\n",
    "print(\"EOS:\", sp.eos_id())\n",
    "print(\"UNK:\", sp.unk_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28c39a3f-8074-4afb-8a58-dc214069fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder_only_gpt import My_GPT_model_SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1bdb2727-0838-41f3-96ce-6e171519f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # --------------------\n",
    "    # Model architecture\n",
    "    # --------------------\n",
    "    \"model\": {\n",
    "        \"vocab_size\": 32768,\n",
    "        \"d_model\": 512,\n",
    "        \"n_layer\": 12,\n",
    "        \"n_head\": 8,\n",
    "        \"d_ff\": 2048,\n",
    "        \"seq_len\": 512,\n",
    "        \"dropout\": 0.1,\n",
    "        \"weight_tying\": True,\n",
    "        \"norm_type\": \"rmsnorm\",\n",
    "        \"ffn_type\": \"swiglu\"\n",
    "    },\n",
    "\n",
    "    # --------------------\n",
    "    # Training (SFT)\n",
    "    # --------------------\n",
    "    \"train\": {\n",
    "        \"batch_size\": 1,\n",
    "        \"micro_batch_size\": 1,     # future gradient accumulation\n",
    "        \"grad_accum_steps\": 1,\n",
    "        \"epochs\": 2,\n",
    "        \"lr\": 1e-5,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"grad_clip\": 1.0,\n",
    "        \"label_smoothing\": 0.0,\n",
    "        \"ignore_index\": -100,\n",
    "        \"fp16\": True,              # future ready\n",
    "        \"bf16\": False,\n",
    "        \"seed\": 42\n",
    "    },\n",
    "\n",
    "    # --------------------\n",
    "    # Data\n",
    "    # --------------------\n",
    "    \"data\": {\n",
    "        \"dataset\": \"hindi_sft_v1\",\n",
    "        \"format\": \"### प्रश्न: / ### उत्तर:\",\n",
    "        \"pad_token_id\": 0,\n",
    "        \"bos_token_id\": 2, \n",
    "        \"eos_token_id\": 3,\n",
    "        \"max_seq_len\": 512,\n",
    "        \"mask_prompt\": True        # loss only on answer\n",
    "    },\n",
    "\n",
    "    # --------------------\n",
    "    # Logging / Checkpoint\n",
    "    # --------------------\n",
    "    \"logging\": {\n",
    "        \"project\": \"HindiGPT-SFT\",\n",
    "        \"log_every\": 50,\n",
    "        \"eval_every\": 2000,\n",
    "        \"save_every\": 7000,\n",
    "        \"save_dir\": \"checkpoints_sft\",\n",
    "        \"wandb\": True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "122718f6-6ae0-49e3-bee3-932598fc1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = My_GPT_model_SFT(\n",
    "    vocab_size=CONFIG[\"model\"][\"vocab_size\"], num_layers=CONFIG[\"model\"][\"n_layer\"],\n",
    "    d_model=CONFIG[\"model\"][\"d_model\"], d_ff=CONFIG[\"model\"][\"d_ff\"],\n",
    "    num_heads=CONFIG[\"model\"][\"n_head\"], seq_len=CONFIG[\"model\"][\"seq_len\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dead7e16-a0e9-4e18-acfe-c70e727043f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights from checkpoints_HindiGPT-v1_step280000.pt\n",
      "Loaded pretrained model with missing keys: ['decoder.layers.0.masked_mha.q_base.weight', 'decoder.layers.0.masked_mha.q_base.bias', 'decoder.layers.0.masked_mha.k_base.weight', 'decoder.layers.0.masked_mha.k_base.bias', 'decoder.layers.0.masked_mha.v_base.weight', 'decoder.layers.0.masked_mha.v_base.bias', 'decoder.layers.0.masked_mha.q_proj.weight', 'decoder.layers.0.masked_mha.q_proj.bias', 'decoder.layers.0.masked_mha.q_proj.lora_A.weight', 'decoder.layers.0.masked_mha.q_proj.lora_B.weight', 'decoder.layers.0.masked_mha.k_proj.weight', 'decoder.layers.0.masked_mha.k_proj.bias', 'decoder.layers.0.masked_mha.k_proj.lora_A.weight', 'decoder.layers.0.masked_mha.k_proj.lora_B.weight', 'decoder.layers.0.masked_mha.v_proj.weight', 'decoder.layers.0.masked_mha.v_proj.bias', 'decoder.layers.0.masked_mha.v_proj.lora_A.weight', 'decoder.layers.0.masked_mha.v_proj.lora_B.weight', 'decoder.layers.1.masked_mha.q_base.weight', 'decoder.layers.1.masked_mha.q_base.bias', 'decoder.layers.1.masked_mha.k_base.weight', 'decoder.layers.1.masked_mha.k_base.bias', 'decoder.layers.1.masked_mha.v_base.weight', 'decoder.layers.1.masked_mha.v_base.bias', 'decoder.layers.1.masked_mha.q_proj.weight', 'decoder.layers.1.masked_mha.q_proj.bias', 'decoder.layers.1.masked_mha.q_proj.lora_A.weight', 'decoder.layers.1.masked_mha.q_proj.lora_B.weight', 'decoder.layers.1.masked_mha.k_proj.weight', 'decoder.layers.1.masked_mha.k_proj.bias', 'decoder.layers.1.masked_mha.k_proj.lora_A.weight', 'decoder.layers.1.masked_mha.k_proj.lora_B.weight', 'decoder.layers.1.masked_mha.v_proj.weight', 'decoder.layers.1.masked_mha.v_proj.bias', 'decoder.layers.1.masked_mha.v_proj.lora_A.weight', 'decoder.layers.1.masked_mha.v_proj.lora_B.weight', 'decoder.layers.2.masked_mha.q_base.weight', 'decoder.layers.2.masked_mha.q_base.bias', 'decoder.layers.2.masked_mha.k_base.weight', 'decoder.layers.2.masked_mha.k_base.bias', 'decoder.layers.2.masked_mha.v_base.weight', 'decoder.layers.2.masked_mha.v_base.bias', 'decoder.layers.2.masked_mha.q_proj.weight', 'decoder.layers.2.masked_mha.q_proj.bias', 'decoder.layers.2.masked_mha.q_proj.lora_A.weight', 'decoder.layers.2.masked_mha.q_proj.lora_B.weight', 'decoder.layers.2.masked_mha.k_proj.weight', 'decoder.layers.2.masked_mha.k_proj.bias', 'decoder.layers.2.masked_mha.k_proj.lora_A.weight', 'decoder.layers.2.masked_mha.k_proj.lora_B.weight', 'decoder.layers.2.masked_mha.v_proj.weight', 'decoder.layers.2.masked_mha.v_proj.bias', 'decoder.layers.2.masked_mha.v_proj.lora_A.weight', 'decoder.layers.2.masked_mha.v_proj.lora_B.weight', 'decoder.layers.3.masked_mha.q_base.weight', 'decoder.layers.3.masked_mha.q_base.bias', 'decoder.layers.3.masked_mha.k_base.weight', 'decoder.layers.3.masked_mha.k_base.bias', 'decoder.layers.3.masked_mha.v_base.weight', 'decoder.layers.3.masked_mha.v_base.bias', 'decoder.layers.3.masked_mha.q_proj.weight', 'decoder.layers.3.masked_mha.q_proj.bias', 'decoder.layers.3.masked_mha.q_proj.lora_A.weight', 'decoder.layers.3.masked_mha.q_proj.lora_B.weight', 'decoder.layers.3.masked_mha.k_proj.weight', 'decoder.layers.3.masked_mha.k_proj.bias', 'decoder.layers.3.masked_mha.k_proj.lora_A.weight', 'decoder.layers.3.masked_mha.k_proj.lora_B.weight', 'decoder.layers.3.masked_mha.v_proj.weight', 'decoder.layers.3.masked_mha.v_proj.bias', 'decoder.layers.3.masked_mha.v_proj.lora_A.weight', 'decoder.layers.3.masked_mha.v_proj.lora_B.weight', 'decoder.layers.4.masked_mha.q_base.weight', 'decoder.layers.4.masked_mha.q_base.bias', 'decoder.layers.4.masked_mha.k_base.weight', 'decoder.layers.4.masked_mha.k_base.bias', 'decoder.layers.4.masked_mha.v_base.weight', 'decoder.layers.4.masked_mha.v_base.bias', 'decoder.layers.4.masked_mha.q_proj.weight', 'decoder.layers.4.masked_mha.q_proj.bias', 'decoder.layers.4.masked_mha.q_proj.lora_A.weight', 'decoder.layers.4.masked_mha.q_proj.lora_B.weight', 'decoder.layers.4.masked_mha.k_proj.weight', 'decoder.layers.4.masked_mha.k_proj.bias', 'decoder.layers.4.masked_mha.k_proj.lora_A.weight', 'decoder.layers.4.masked_mha.k_proj.lora_B.weight', 'decoder.layers.4.masked_mha.v_proj.weight', 'decoder.layers.4.masked_mha.v_proj.bias', 'decoder.layers.4.masked_mha.v_proj.lora_A.weight', 'decoder.layers.4.masked_mha.v_proj.lora_B.weight', 'decoder.layers.5.masked_mha.q_base.weight', 'decoder.layers.5.masked_mha.q_base.bias', 'decoder.layers.5.masked_mha.k_base.weight', 'decoder.layers.5.masked_mha.k_base.bias', 'decoder.layers.5.masked_mha.v_base.weight', 'decoder.layers.5.masked_mha.v_base.bias', 'decoder.layers.5.masked_mha.q_proj.weight', 'decoder.layers.5.masked_mha.q_proj.bias', 'decoder.layers.5.masked_mha.q_proj.lora_A.weight', 'decoder.layers.5.masked_mha.q_proj.lora_B.weight', 'decoder.layers.5.masked_mha.k_proj.weight', 'decoder.layers.5.masked_mha.k_proj.bias', 'decoder.layers.5.masked_mha.k_proj.lora_A.weight', 'decoder.layers.5.masked_mha.k_proj.lora_B.weight', 'decoder.layers.5.masked_mha.v_proj.weight', 'decoder.layers.5.masked_mha.v_proj.bias', 'decoder.layers.5.masked_mha.v_proj.lora_A.weight', 'decoder.layers.5.masked_mha.v_proj.lora_B.weight', 'decoder.layers.6.masked_mha.q_base.weight', 'decoder.layers.6.masked_mha.q_base.bias', 'decoder.layers.6.masked_mha.k_base.weight', 'decoder.layers.6.masked_mha.k_base.bias', 'decoder.layers.6.masked_mha.v_base.weight', 'decoder.layers.6.masked_mha.v_base.bias', 'decoder.layers.6.masked_mha.q_proj.weight', 'decoder.layers.6.masked_mha.q_proj.bias', 'decoder.layers.6.masked_mha.q_proj.lora_A.weight', 'decoder.layers.6.masked_mha.q_proj.lora_B.weight', 'decoder.layers.6.masked_mha.k_proj.weight', 'decoder.layers.6.masked_mha.k_proj.bias', 'decoder.layers.6.masked_mha.k_proj.lora_A.weight', 'decoder.layers.6.masked_mha.k_proj.lora_B.weight', 'decoder.layers.6.masked_mha.v_proj.weight', 'decoder.layers.6.masked_mha.v_proj.bias', 'decoder.layers.6.masked_mha.v_proj.lora_A.weight', 'decoder.layers.6.masked_mha.v_proj.lora_B.weight', 'decoder.layers.7.masked_mha.q_base.weight', 'decoder.layers.7.masked_mha.q_base.bias', 'decoder.layers.7.masked_mha.k_base.weight', 'decoder.layers.7.masked_mha.k_base.bias', 'decoder.layers.7.masked_mha.v_base.weight', 'decoder.layers.7.masked_mha.v_base.bias', 'decoder.layers.7.masked_mha.q_proj.weight', 'decoder.layers.7.masked_mha.q_proj.bias', 'decoder.layers.7.masked_mha.q_proj.lora_A.weight', 'decoder.layers.7.masked_mha.q_proj.lora_B.weight', 'decoder.layers.7.masked_mha.k_proj.weight', 'decoder.layers.7.masked_mha.k_proj.bias', 'decoder.layers.7.masked_mha.k_proj.lora_A.weight', 'decoder.layers.7.masked_mha.k_proj.lora_B.weight', 'decoder.layers.7.masked_mha.v_proj.weight', 'decoder.layers.7.masked_mha.v_proj.bias', 'decoder.layers.7.masked_mha.v_proj.lora_A.weight', 'decoder.layers.7.masked_mha.v_proj.lora_B.weight', 'decoder.layers.8.masked_mha.q_base.weight', 'decoder.layers.8.masked_mha.q_base.bias', 'decoder.layers.8.masked_mha.k_base.weight', 'decoder.layers.8.masked_mha.k_base.bias', 'decoder.layers.8.masked_mha.v_base.weight', 'decoder.layers.8.masked_mha.v_base.bias', 'decoder.layers.8.masked_mha.q_proj.weight', 'decoder.layers.8.masked_mha.q_proj.bias', 'decoder.layers.8.masked_mha.q_proj.lora_A.weight', 'decoder.layers.8.masked_mha.q_proj.lora_B.weight', 'decoder.layers.8.masked_mha.k_proj.weight', 'decoder.layers.8.masked_mha.k_proj.bias', 'decoder.layers.8.masked_mha.k_proj.lora_A.weight', 'decoder.layers.8.masked_mha.k_proj.lora_B.weight', 'decoder.layers.8.masked_mha.v_proj.weight', 'decoder.layers.8.masked_mha.v_proj.bias', 'decoder.layers.8.masked_mha.v_proj.lora_A.weight', 'decoder.layers.8.masked_mha.v_proj.lora_B.weight', 'decoder.layers.9.masked_mha.q_base.weight', 'decoder.layers.9.masked_mha.q_base.bias', 'decoder.layers.9.masked_mha.k_base.weight', 'decoder.layers.9.masked_mha.k_base.bias', 'decoder.layers.9.masked_mha.v_base.weight', 'decoder.layers.9.masked_mha.v_base.bias', 'decoder.layers.9.masked_mha.q_proj.weight', 'decoder.layers.9.masked_mha.q_proj.bias', 'decoder.layers.9.masked_mha.q_proj.lora_A.weight', 'decoder.layers.9.masked_mha.q_proj.lora_B.weight', 'decoder.layers.9.masked_mha.k_proj.weight', 'decoder.layers.9.masked_mha.k_proj.bias', 'decoder.layers.9.masked_mha.k_proj.lora_A.weight', 'decoder.layers.9.masked_mha.k_proj.lora_B.weight', 'decoder.layers.9.masked_mha.v_proj.weight', 'decoder.layers.9.masked_mha.v_proj.bias', 'decoder.layers.9.masked_mha.v_proj.lora_A.weight', 'decoder.layers.9.masked_mha.v_proj.lora_B.weight', 'decoder.layers.10.masked_mha.q_base.weight', 'decoder.layers.10.masked_mha.q_base.bias', 'decoder.layers.10.masked_mha.k_base.weight', 'decoder.layers.10.masked_mha.k_base.bias', 'decoder.layers.10.masked_mha.v_base.weight', 'decoder.layers.10.masked_mha.v_base.bias', 'decoder.layers.10.masked_mha.q_proj.weight', 'decoder.layers.10.masked_mha.q_proj.bias', 'decoder.layers.10.masked_mha.q_proj.lora_A.weight', 'decoder.layers.10.masked_mha.q_proj.lora_B.weight', 'decoder.layers.10.masked_mha.k_proj.weight', 'decoder.layers.10.masked_mha.k_proj.bias', 'decoder.layers.10.masked_mha.k_proj.lora_A.weight', 'decoder.layers.10.masked_mha.k_proj.lora_B.weight', 'decoder.layers.10.masked_mha.v_proj.weight', 'decoder.layers.10.masked_mha.v_proj.bias', 'decoder.layers.10.masked_mha.v_proj.lora_A.weight', 'decoder.layers.10.masked_mha.v_proj.lora_B.weight', 'decoder.layers.11.masked_mha.q_base.weight', 'decoder.layers.11.masked_mha.q_base.bias', 'decoder.layers.11.masked_mha.k_base.weight', 'decoder.layers.11.masked_mha.k_base.bias', 'decoder.layers.11.masked_mha.v_base.weight', 'decoder.layers.11.masked_mha.v_base.bias', 'decoder.layers.11.masked_mha.q_proj.weight', 'decoder.layers.11.masked_mha.q_proj.bias', 'decoder.layers.11.masked_mha.q_proj.lora_A.weight', 'decoder.layers.11.masked_mha.q_proj.lora_B.weight', 'decoder.layers.11.masked_mha.k_proj.weight', 'decoder.layers.11.masked_mha.k_proj.bias', 'decoder.layers.11.masked_mha.k_proj.lora_A.weight', 'decoder.layers.11.masked_mha.k_proj.lora_B.weight', 'decoder.layers.11.masked_mha.v_proj.weight', 'decoder.layers.11.masked_mha.v_proj.bias', 'decoder.layers.11.masked_mha.v_proj.lora_A.weight', 'decoder.layers.11.masked_mha.v_proj.lora_B.weight']\n",
      "************\n",
      "unexpected keys: ['decoder.layers.0.masked_mha.Q.weight', 'decoder.layers.0.masked_mha.Q.bias', 'decoder.layers.0.masked_mha.K.weight', 'decoder.layers.0.masked_mha.K.bias', 'decoder.layers.0.masked_mha.V.weight', 'decoder.layers.0.masked_mha.V.bias', 'decoder.layers.1.masked_mha.Q.weight', 'decoder.layers.1.masked_mha.Q.bias', 'decoder.layers.1.masked_mha.K.weight', 'decoder.layers.1.masked_mha.K.bias', 'decoder.layers.1.masked_mha.V.weight', 'decoder.layers.1.masked_mha.V.bias', 'decoder.layers.2.masked_mha.Q.weight', 'decoder.layers.2.masked_mha.Q.bias', 'decoder.layers.2.masked_mha.K.weight', 'decoder.layers.2.masked_mha.K.bias', 'decoder.layers.2.masked_mha.V.weight', 'decoder.layers.2.masked_mha.V.bias', 'decoder.layers.3.masked_mha.Q.weight', 'decoder.layers.3.masked_mha.Q.bias', 'decoder.layers.3.masked_mha.K.weight', 'decoder.layers.3.masked_mha.K.bias', 'decoder.layers.3.masked_mha.V.weight', 'decoder.layers.3.masked_mha.V.bias', 'decoder.layers.4.masked_mha.Q.weight', 'decoder.layers.4.masked_mha.Q.bias', 'decoder.layers.4.masked_mha.K.weight', 'decoder.layers.4.masked_mha.K.bias', 'decoder.layers.4.masked_mha.V.weight', 'decoder.layers.4.masked_mha.V.bias', 'decoder.layers.5.masked_mha.Q.weight', 'decoder.layers.5.masked_mha.Q.bias', 'decoder.layers.5.masked_mha.K.weight', 'decoder.layers.5.masked_mha.K.bias', 'decoder.layers.5.masked_mha.V.weight', 'decoder.layers.5.masked_mha.V.bias', 'decoder.layers.6.masked_mha.Q.weight', 'decoder.layers.6.masked_mha.Q.bias', 'decoder.layers.6.masked_mha.K.weight', 'decoder.layers.6.masked_mha.K.bias', 'decoder.layers.6.masked_mha.V.weight', 'decoder.layers.6.masked_mha.V.bias', 'decoder.layers.7.masked_mha.Q.weight', 'decoder.layers.7.masked_mha.Q.bias', 'decoder.layers.7.masked_mha.K.weight', 'decoder.layers.7.masked_mha.K.bias', 'decoder.layers.7.masked_mha.V.weight', 'decoder.layers.7.masked_mha.V.bias', 'decoder.layers.8.masked_mha.Q.weight', 'decoder.layers.8.masked_mha.Q.bias', 'decoder.layers.8.masked_mha.K.weight', 'decoder.layers.8.masked_mha.K.bias', 'decoder.layers.8.masked_mha.V.weight', 'decoder.layers.8.masked_mha.V.bias', 'decoder.layers.9.masked_mha.Q.weight', 'decoder.layers.9.masked_mha.Q.bias', 'decoder.layers.9.masked_mha.K.weight', 'decoder.layers.9.masked_mha.K.bias', 'decoder.layers.9.masked_mha.V.weight', 'decoder.layers.9.masked_mha.V.bias', 'decoder.layers.10.masked_mha.Q.weight', 'decoder.layers.10.masked_mha.Q.bias', 'decoder.layers.10.masked_mha.K.weight', 'decoder.layers.10.masked_mha.K.bias', 'decoder.layers.10.masked_mha.V.weight', 'decoder.layers.10.masked_mha.V.bias', 'decoder.layers.11.masked_mha.Q.weight', 'decoder.layers.11.masked_mha.Q.bias', 'decoder.layers.11.masked_mha.K.weight', 'decoder.layers.11.masked_mha.K.bias', 'decoder.layers.11.masked_mha.V.weight', 'decoder.layers.11.masked_mha.V.bias']\n"
     ]
    }
   ],
   "source": [
    "pretrained_path = \"checkpoints_HindiGPT-v1_step280000.pt\"  # <-- put actual pretrained checkpoint path here\n",
    "\n",
    "if os.path.isfile(pretrained_path):\n",
    "    print(f\"Loading pretrained weights from {pretrained_path}\")\n",
    "    checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "    \n",
    "    # If checkpoint has key \"model\" holding weights, else use checkpoint directly\n",
    "    state_dict = checkpoint.get(\"model\", checkpoint)\n",
    "    \n",
    "    # Remove any unwanted prefixes (like _orig_mod.) if present, matching your load_checkpoint code\n",
    "    new_state = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "    \n",
    "    missing, unexpected = model.load_state_dict(new_state, strict=False)\n",
    "    print(f\"Loaded pretrained model with missing keys: {missing}\")\n",
    "    print(\"************\")\n",
    "    print(f\"unexpected keys: {unexpected}\")\n",
    "else:\n",
    "    print(\"Pretrained model checkpoint not found, training from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfaf3020-f771-47df-a112-feddeb0cbdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My_GPT_model_SFT(\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(32768, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Decoder_GPT_Block(\n",
       "        (swi_glu): SwiGLU_FFN(\n",
       "          (w1): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (w2): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (w3): Linear(in_features=1536, out_features=512, bias=False)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (masked_mha): Masked_MHA_LORA(\n",
       "          (q_base): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (k_base): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_base): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): LoRALinear(\n",
       "            (lora_A): Linear(in_features=512, out_features=8, bias=False)\n",
       "            (lora_B): Linear(in_features=8, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (k_proj): LoRALinear(\n",
       "            (lora_A): Linear(in_features=512, out_features=8, bias=False)\n",
       "            (lora_B): Linear(in_features=8, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (v_proj): LoRALinear(\n",
       "            (lora_A): Linear(in_features=512, out_features=8, bias=False)\n",
       "            (lora_B): Linear(in_features=8, out_features=512, bias=False)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (rms_norm0): RMSNorm()\n",
       "        (rms_norm1): RMSNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75c729df-9bc5-4b59-9ffc-09e5514d404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (embedding): Embedding(32768, 512)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x Decoder_GPT_Block(\n",
       "      (swi_glu): SwiGLU_FFN(\n",
       "        (w1): Linear(in_features=512, out_features=1536, bias=False)\n",
       "        (w2): Linear(in_features=512, out_features=1536, bias=False)\n",
       "        (w3): Linear(in_features=1536, out_features=512, bias=False)\n",
       "        (act): SiLU()\n",
       "      )\n",
       "      (masked_mha): Masked_MHA_LORA(\n",
       "        (q_base): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (k_base): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (v_base): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (q_proj): LoRALinear(\n",
       "          (lora_A): Linear(in_features=512, out_features=8, bias=False)\n",
       "          (lora_B): Linear(in_features=8, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (k_proj): LoRALinear(\n",
       "          (lora_A): Linear(in_features=512, out_features=8, bias=False)\n",
       "          (lora_B): Linear(in_features=8, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (v_proj): LoRALinear(\n",
       "          (lora_A): Linear(in_features=512, out_features=8, bias=False)\n",
       "          (lora_B): Linear(in_features=8, out_features=512, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (rms_norm0): RMSNorm()\n",
       "      (rms_norm1): RMSNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c048c5ca-0688-4024-9613-0508695b7065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(32768, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d0c5039-a729-4d1f-aa0e-69aeb1d5c53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.6479e-03, -5.1934e-02,  1.9765e-02,  ...,  4.8727e-02,\n",
       "          2.1490e-03,  2.9600e-02],\n",
       "        [ 2.1276e-03, -3.7330e-02,  1.1916e-02,  ...,  1.6846e-02,\n",
       "          9.4464e-06,  2.3255e-02],\n",
       "        [ 1.6793e-03, -5.1942e-02,  1.9771e-02,  ...,  4.8732e-02,\n",
       "          2.1496e-03,  2.9585e-02],\n",
       "        ...,\n",
       "        [ 1.6573e-03, -5.1932e-02,  1.9768e-02,  ...,  4.8731e-02,\n",
       "          2.1527e-03,  2.9579e-02],\n",
       "        [ 1.6747e-03, -5.1922e-02,  1.9737e-02,  ...,  4.8732e-02,\n",
       "          2.1439e-03,  2.9594e-02],\n",
       "        [ 1.8618e-03, -5.1502e-02,  1.9627e-02,  ...,  4.7211e-02,\n",
       "          2.2105e-03,  2.9348e-02]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20a9aa9c-2a47-456c-9b09-512ee892e8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.embedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e06579da-41f6-4e1d-9d71-681c561b73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6479e-03, -5.1934e-02,  1.9765e-02,  4.1537e-02, -2.9619e-02,\n",
       "        -3.1721e-02, -3.5112e-02,  7.1186e-03, -6.3270e-03,  2.3410e-02,\n",
       "         4.2177e-02, -3.9054e-02,  5.1253e-02, -5.1261e-01,  2.2189e-02,\n",
       "         2.7451e-02, -8.7450e-03, -3.0652e-01,  1.2234e-03,  9.8096e-03,\n",
       "         2.9875e-02, -2.8258e-01,  1.1134e-01, -4.7863e-02, -1.1598e-01,\n",
       "         1.0249e-02, -1.5890e-02,  3.0105e-02, -5.2984e-02,  4.2057e-02,\n",
       "         7.4862e-02, -8.3000e-03,  2.8148e-02, -9.7618e-02,  1.5783e-02,\n",
       "         3.2441e-02,  1.6196e-01,  3.0731e-02, -2.5335e-01,  2.2948e-02,\n",
       "        -4.9372e-02,  1.3575e-02, -6.1646e-02,  2.1235e-03,  1.6382e-02,\n",
       "         2.7277e-02,  1.2145e-02,  1.1668e-01, -4.0974e-02, -2.4567e-02,\n",
       "         7.2909e-02,  5.0054e-02,  2.9814e-02, -9.4731e-03, -1.3241e-02,\n",
       "         3.2810e-02, -1.4707e-02,  2.0861e-02,  2.5190e-02, -3.7752e-02,\n",
       "         1.0164e-03, -2.4250e-02, -3.4445e-01,  3.8835e-02, -5.2761e-02,\n",
       "        -5.9122e-02,  2.4172e-02,  5.9933e-02,  1.7806e-02, -2.0969e-02,\n",
       "         2.5165e-02,  1.6080e-02, -1.5603e-02, -5.3795e-02,  5.0511e-02,\n",
       "        -2.4778e-02, -1.6160e-02, -4.3478e-02, -2.7882e-02, -1.7878e-02,\n",
       "        -6.6909e-02, -6.2829e-03, -2.5188e-02, -5.1525e-02, -9.5654e-02,\n",
       "        -6.7566e-02,  1.6012e-01, -1.3529e-02,  2.9927e-02, -1.0201e-01,\n",
       "        -8.3738e-02, -1.1734e-01,  1.2642e-02, -2.8072e-01, -3.1494e-02,\n",
       "        -5.2872e-02, -1.4692e-02, -1.3057e-02, -4.5038e-02,  8.1594e-03,\n",
       "        -1.1909e-02,  1.6765e-01, -1.7257e-01, -5.5265e-02,  5.8813e-02,\n",
       "        -4.9189e-02,  2.9516e-02,  7.2103e-03,  3.2130e-02,  1.5077e-02,\n",
       "         1.7595e-02,  4.0611e-02, -1.5352e-02,  1.4728e-02, -4.7153e-02,\n",
       "        -6.3405e-03,  2.3480e-02, -5.1846e-02,  4.4209e-03, -2.7964e-02,\n",
       "         5.6333e-02,  6.6525e-03, -7.2100e-02,  4.3182e-01,  1.3180e-01,\n",
       "        -6.4647e-03,  1.7885e-01, -5.0517e-03, -2.9638e-01, -1.1361e-01,\n",
       "        -2.1439e-02,  2.1202e-01, -1.2060e-01,  3.8431e-02, -2.7560e-02,\n",
       "        -1.8239e-02,  1.7136e-02, -2.4015e-02,  4.0848e-02,  5.1677e-04,\n",
       "        -4.6821e-02,  1.1589e-01, -3.0500e-02,  1.1117e-01,  8.5551e-02,\n",
       "         4.6525e-02, -1.3609e-02,  6.5405e-02,  2.9698e-02, -6.3272e-02,\n",
       "         4.3939e-02, -1.6008e-02,  6.9057e-03,  2.5495e-03,  3.1316e-02,\n",
       "        -3.3158e-02, -7.7030e-02, -4.8107e-02,  3.8143e-02,  1.3821e-01,\n",
       "        -1.9100e-02,  3.4191e-02, -2.4421e-02,  4.0667e-03,  1.0996e-01,\n",
       "         1.0064e-01, -2.6946e-02,  4.1078e-04, -5.1949e-02,  2.0013e-02,\n",
       "         3.9844e-02,  4.0560e-03,  2.6510e-02,  5.9373e-02,  3.6195e-02,\n",
       "         3.4026e-02, -3.0683e-02, -2.5798e-02,  8.3311e-02,  1.7994e-02,\n",
       "        -3.8718e-02, -2.6372e-02,  9.9729e-02,  1.8142e-02, -4.1279e-02,\n",
       "        -3.0526e-02,  8.8269e-02, -1.9157e-02, -4.3007e-02,  1.9765e-02,\n",
       "         6.6059e-03,  7.4237e-04, -4.8467e-02, -5.9004e-02,  7.8461e-03,\n",
       "         3.3298e-01,  1.4685e-02, -2.9962e-03, -4.0110e-02,  6.6771e-02,\n",
       "        -1.3092e-02, -3.6737e-02, -2.4735e-02,  9.7693e-02, -1.0920e-02,\n",
       "        -3.8238e-02, -3.5533e-02, -2.8112e-02,  1.7948e-02, -9.9619e-02,\n",
       "         6.7007e-02, -3.0451e-02,  2.9775e-02,  5.9747e-02,  6.6128e-03,\n",
       "         3.5530e-02,  2.3797e-02,  3.6544e-02, -3.0191e-02,  3.9406e-02,\n",
       "         1.7049e-02,  2.0686e-01, -4.4928e-01,  3.6583e-03,  1.2123e-01,\n",
       "         2.3284e-02, -5.9986e-02,  4.0535e-02, -3.6724e-02,  1.9433e-01,\n",
       "         1.0711e-02,  5.6929e-03, -7.0463e-02,  4.7401e-02, -5.9286e-02,\n",
       "         8.9848e-02,  3.2084e-02,  1.1474e-02,  5.7122e-02, -6.6502e-03,\n",
       "         4.6961e-02, -1.1372e-02, -2.1623e-02, -5.4851e-03, -2.6887e-02,\n",
       "        -4.9932e-02,  4.4305e-01, -1.4289e-02,  3.4627e-02, -3.4375e-02,\n",
       "         9.8414e-03, -2.0030e-01,  6.4920e-03,  1.0553e-02,  7.9902e-02,\n",
       "         1.2181e-02, -4.3063e-02,  8.6449e-03, -2.4977e-02, -2.7742e-02,\n",
       "        -1.3697e-02,  4.4048e-02, -1.2381e-02, -8.2059e-03, -3.8592e-02,\n",
       "        -1.7471e-02, -1.7096e+00,  9.3900e-02,  5.8771e-03,  2.2636e-02,\n",
       "        -4.7028e-02, -5.1327e-02,  2.8612e-03,  1.9397e-02, -3.4563e-02,\n",
       "         1.0167e-01, -7.5520e-03, -1.0508e-02, -9.8492e-02, -3.5459e-02,\n",
       "         9.0651e-03,  5.2579e-02,  6.1089e-03, -1.0159e-01,  4.9622e-02,\n",
       "         3.2732e-02, -3.1654e-02, -2.9938e-02,  6.8498e-03,  5.6683e-02,\n",
       "        -1.8159e-02, -2.9477e-03, -2.2804e-03, -8.8304e-03, -6.0492e-02,\n",
       "         4.9036e-02, -1.3585e-02, -7.5493e-02, -1.4187e-02,  2.7721e-03,\n",
       "         7.9380e-02,  5.2876e-02, -1.2511e-01,  5.3795e-03, -3.6486e-02,\n",
       "         6.8994e-02, -4.3866e-02,  4.5618e-03,  5.0199e-02, -1.1630e-02,\n",
       "         2.3019e-01, -1.6507e-02, -4.1122e-02,  3.2228e-02, -6.1699e-02,\n",
       "         3.3395e-02,  7.5478e-02,  3.5962e-02, -2.4957e-03, -1.5715e-03,\n",
       "         4.2509e-03,  6.0100e-02,  2.9832e-02,  2.3425e-02, -3.7228e-02,\n",
       "        -7.2542e-01,  1.3447e-02,  1.9376e-02,  1.5860e-02, -5.7612e-02,\n",
       "         3.3619e-02,  2.3510e-02, -3.8369e-02,  5.7861e-03,  2.7670e-01,\n",
       "         6.2287e-03, -3.9329e-02, -3.3079e-02,  4.8729e-02, -1.5208e-01,\n",
       "         1.8003e-02,  1.8513e-02,  3.0532e-02, -4.8272e-02, -5.1612e-02,\n",
       "        -2.4917e-01,  6.0744e-03,  2.3301e-02, -6.9829e-02, -9.4139e-04,\n",
       "        -6.1931e-02, -5.3500e-03,  1.7203e-02, -5.9360e-02,  8.6133e-02,\n",
       "         4.0068e-03, -8.0152e-02, -2.9373e-02, -2.2627e-01,  8.8325e-03,\n",
       "        -4.4804e-02,  3.4724e-02,  4.0183e-02,  4.3277e-03, -2.0032e-02,\n",
       "        -3.2487e-03, -9.6656e-03, -1.7793e-02, -4.4237e-03,  6.7976e-04,\n",
       "        -4.1895e-02, -3.5840e-02,  1.9151e-02, -2.9695e-03,  2.1167e-02,\n",
       "         1.8846e-02,  3.7843e-02,  7.5127e-02,  1.4181e-02, -4.0185e-02,\n",
       "         1.3767e-02, -1.2740e-02, -6.4415e-02, -2.2326e-01,  5.3806e-02,\n",
       "        -5.9389e-02, -5.8158e-02,  3.8099e-02, -1.1977e-01,  4.2688e-02,\n",
       "         8.6389e-03,  1.3324e-01, -3.7437e-02, -2.5582e-02, -1.9681e-02,\n",
       "        -7.8201e-03,  5.7909e-03, -3.8071e-02, -2.5086e-02, -6.5130e-03,\n",
       "        -9.3358e-03, -1.4866e-02, -7.5917e-02,  8.3259e-03,  4.1236e-03,\n",
       "         6.6962e-02, -3.2143e-01,  2.7224e-02,  3.7732e-02,  1.2817e-02,\n",
       "        -1.7887e-02, -1.1526e-03,  1.2743e-02,  4.5160e-02,  3.0322e-02,\n",
       "         5.5220e-02, -4.3283e-02,  9.1179e-02, -4.9519e-02, -4.7099e-02,\n",
       "         6.8514e-03, -1.9999e-02, -4.5327e-03,  8.8771e-02, -2.1423e-02,\n",
       "         1.9576e-02,  6.3890e-02,  6.7405e-02,  2.7320e-02,  7.5089e-02,\n",
       "         2.9841e-02, -2.8344e-01, -2.3704e-03, -3.4176e-02, -1.4017e-02,\n",
       "        -3.1758e-02, -3.4325e-02,  5.9111e-03,  3.3079e-03, -1.6933e-01,\n",
       "         4.2576e-02,  1.4504e-01, -4.2994e-03, -3.2546e-03, -2.3439e-02,\n",
       "        -8.3427e-02,  5.1000e-02,  2.5664e-02, -5.1309e-02,  2.2773e-01,\n",
       "         8.3371e-02, -2.3797e-03,  2.5804e-02, -6.2536e-02, -1.2122e-02,\n",
       "        -9.8535e-03,  1.5975e-02,  6.2113e-02,  4.8237e-04,  4.1784e-02,\n",
       "        -8.1583e-02, -2.0104e-02,  1.0263e-01,  1.0223e-01, -5.2560e-02,\n",
       "         7.0127e-02,  6.3949e-02,  4.2107e-02,  4.8711e-01,  4.1414e-02,\n",
       "        -1.2925e-02,  2.2834e-01, -3.2006e-02, -1.6362e-02, -2.2109e-01,\n",
       "         1.5358e-02,  1.3129e-01,  2.6592e-02, -2.8359e-02,  5.3122e-02,\n",
       "         4.9394e-04, -6.2165e-02, -4.1542e-02, -1.4573e-01,  1.1581e-02,\n",
       "         1.3406e-01, -1.0847e-02,  4.4611e-02,  2.6290e-03,  2.0535e-02,\n",
       "         5.4325e-03,  1.8871e-02,  4.8358e-03, -2.5635e-01,  2.0087e-02,\n",
       "         2.2776e-02, -4.6023e-02, -4.0028e-03, -2.4132e-02, -2.0688e-02,\n",
       "         2.9852e-01, -1.2567e-02,  1.5404e-02,  4.9503e-02, -2.4411e-02,\n",
       "        -3.3225e-02,  1.1193e-01,  4.5099e-02,  2.7068e-02,  4.8727e-02,\n",
       "         2.1490e-03,  2.9600e-02], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.decoder.embedding.weight[0].shape)\n",
    "model.decoder.embedding.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39a7d893-6c6e-49fe-8292-e1b83f0e4910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decoder.embedding.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c68078f9-0f06-408a-b95b-addc671c378d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight is model.decoder.embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67c706b7-e190-4c4d-92a3-d6b90c717f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3717, 1020, 11, 91]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode(\"स्वस्थ रहने के लिए\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed5a867d-7b85-4b11-8888-17590f8fddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.decoder.embedding.max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "731b6599-06b8-412e-a67e-cffc39ac0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = spm.SentencePieceProcessor(model_file=\"hindi_tokenizer_new.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c86a46f7-d112-4c82-8102-2feed727fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class SFT_Dataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        \n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.answer_key = \"### उत्तर:\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data[index][\"text\"]\n",
    "\n",
    "        BOS = CONFIG[\"data\"][\"bos_token_id\"]\n",
    "        EOS = CONFIG[\"data\"][\"eos_token_id\"]\n",
    "\n",
    "        full_ids = [BOS] + self.tokenizer.encode(text) + [EOS]\n",
    "\n",
    "        pos = text.find(self.answer_key)\n",
    "        if pos == -1:\n",
    "            pos = len(text)\n",
    "\n",
    "        prompt_text = text[:pos + len(self.answer_key)]\n",
    "        prompt_ids = [BOS] + self.tokenizer.encode(prompt_text)\n",
    "\n",
    "        min_len = min(len(prompt_ids), len(full_ids))\n",
    "        answer_start = 0\n",
    "        for i in range(min_len, 0, -1):\n",
    "            if prompt_ids[:i] == full_ids[:i]:\n",
    "                answer_start = i\n",
    "                break\n",
    "\n",
    "        input_ids = torch.tensor(full_ids, dtype=torch.long)\n",
    "\n",
    "        if CONFIG[\"data\"][\"mask_prompt\"] and answer_start > 0:\n",
    "            labels = torch.full_like(input_ids, -100)\n",
    "            labels[answer_start:] = input_ids[answer_start:]\n",
    "        else:\n",
    "            labels = input_ids.clone()\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\": labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c76411e-5ac9-413b-ad03-a59e07db2fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB: 32768\n",
      "BOS: 2\n",
      "EOS: 3\n",
      "PAD: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"VOCAB:\", sp.get_piece_size())\n",
    "print(\"BOS:\", CONFIG[\"data\"][\"bos_token_id\"])\n",
    "print(\"EOS:\", CONFIG[\"data\"][\"eos_token_id\"])\n",
    "print(\"PAD:\", CONFIG[\"data\"][\"pad_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02018c58-9854-49a1-a423-129e624dc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_sample(dataset, idx=0):\n",
    "    sample = dataset[idx]\n",
    "\n",
    "    input_ids = sample[\"input_ids\"]\n",
    "    labels = sample[\"labels\"]\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"INPUT IDS:\", input_ids.tolist())\n",
    "    print(\"LABELS   :\", labels.tolist())\n",
    "\n",
    "    print(\"\\nDECODED FULL:\")\n",
    "    print(sp.decode(input_ids.tolist()))\n",
    "\n",
    "    answer_tokens = [\n",
    "        t for t, l in zip(input_ids.tolist(), labels.tolist()) if l != -100\n",
    "    ]\n",
    "\n",
    "    print(\"\\nDECODED ANSWER ONLY:\")\n",
    "    print(sp.decode(answer_tokens))\n",
    "\n",
    "    print(\"\\nBOS OK:\", input_ids[0].item() == sp.bos_id())\n",
    "    print(\"EOS OK:\", input_ids[-1].item() == sp.eos_id())\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7d640bc2-0c47-4eb2-ae24-21f02ce9e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = []\n",
    "with open(\"alpaca_hindi_sft_clean.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72cb4644-bb23-4947-967f-67d854970491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### प्रश्न:\\nतीन प्राथमिक रंग कौन से हैं?\\n\\n### उत्तर:\\nतीन प्राथमिक रंग लाल, नीला और पीला हैं। इन रंगों को प्राथमिक कहा जाता है क्योंकि इन्हें अन्य रंगों को मिलाकर नहीं बनाया जा सकता है और अन्य सभी रंगों को विभिन्न अनुपातों में मिलाकर बनाया जा सकता है। प्रकाश के लिए उपयोग की जाने वाली योगात्मक रंग प्रणाली में, प्राथमिक रंग लाल, हरा और नीला (आर. जी. बी.) हैं।'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data[1]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a95cfc40-0964-4256-b7d3-8dce7dfba30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SFT_Dataset(data, tokenizer=sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a664fe16-d4ce-443e-8f68-335aeee4f4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INPUT IDS: [2, 28843, 1, 2821, 28911, 1, 1970, 357, 1020, 11, 91, 565, 4535, 884, 28869, 1, 832, 28911, 1, 28924, 28889, 10608, 44, 13215, 5479, 1678, 28920, 3010, 393, 38, 778, 2661, 22, 1295, 1005, 11, 2347, 44, 11726, 28879, 6388, 83, 6769, 28879, 23834, 6823, 44, 3717, 10944, 679, 776, 28869, 133, 778, 1358, 28, 12226, 377, 32, 311, 140, 11, 91, 1290, 8777, 3377, 1652, 140, 22, 981, 629, 15, 44, 3497, 5155, 28, 2932, 22, 981, 36, 438, 15, 28869, 1, 28932, 28889, 3420, 3946, 9069, 22, 12531, 2690, 28920, 2286, 12737, 28879, 11664, 44, 4727, 1167, 28, 1566, 1397, 11, 91, 8044, 1634, 15, 28869, 2386, 2296, 253, 32, 253, 11776, 28922, 1887, 11, 6288, 24342, 18105, 8044, 158, 9747, 28938, 1887, 11, 7125, 8044, 40, 2411, 2694, 28869, 1, 28937, 28889, 3839, 4499, 1678, 28920, 3839, 3517, 561, 4499, 2459, 3946, 44, 3754, 2940, 11, 91, 1634, 15, 28869, 133, 3346, 12413, 28, 6124, 140, 28879, 25251, 221, 1545, 311, 22, 2064, 140, 44, 3717, 777, 44, 17259, 311, 40, 1929, 140, 22, 981, 629, 15, 28869, 351, 953, 9747, 32, 11398, 1588, 3263, 40, 2411, 2694, 28869, 3]\n",
      "LABELS   : [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 28924, 28889, 10608, 44, 13215, 5479, 1678, 28920, 3010, 393, 38, 778, 2661, 22, 1295, 1005, 11, 2347, 44, 11726, 28879, 6388, 83, 6769, 28879, 23834, 6823, 44, 3717, 10944, 679, 776, 28869, 133, 778, 1358, 28, 12226, 377, 32, 311, 140, 11, 91, 1290, 8777, 3377, 1652, 140, 22, 981, 629, 15, 44, 3497, 5155, 28, 2932, 22, 981, 36, 438, 15, 28869, 1, 28932, 28889, 3420, 3946, 9069, 22, 12531, 2690, 28920, 2286, 12737, 28879, 11664, 44, 4727, 1167, 28, 1566, 1397, 11, 91, 8044, 1634, 15, 28869, 2386, 2296, 253, 32, 253, 11776, 28922, 1887, 11, 6288, 24342, 18105, 8044, 158, 9747, 28938, 1887, 11, 7125, 8044, 40, 2411, 2694, 28869, 1, 28937, 28889, 3839, 4499, 1678, 28920, 3839, 3517, 561, 4499, 2459, 3946, 44, 3754, 2940, 11, 91, 1634, 15, 28869, 133, 3346, 12413, 28, 6124, 140, 28879, 25251, 221, 1545, 311, 22, 2064, 140, 44, 3717, 777, 44, 17259, 311, 40, 1929, 140, 22, 981, 629, 15, 28869, 351, 953, 9747, 32, 11398, 1588, 3263, 40, 2411, 2694, 28869, 3]\n",
      "\n",
      "DECODED FULL:\n",
      " ⁇  प्रश्न: ⁇ स्वस्थ रहने के लिए तीन सुझाव दें। ⁇  उत्तर: ⁇ 1. संतुलित और पौष्टिक आहार लेंः सुनिश्चित करें कि आपके भोजन में विभिन्न प्रकार के फल और सब्जियां, दुबला प्रोटीन, साबुत अनाज और स्वस्थ वसा शामिल हों। यह आपके शरीर को सर्वोत्तम रूप से कार्य करने के लिए आवश्यक पोषक तत्व प्रदान करने में मदद करता है और पुरानी बीमारियों को रोकने में मदद कर सकता है। ⁇ 2. नियमित शारीरिक गतिविधि में संलग्न रहेंः मजबूत हड्डियों, मांसपेशियों और हृदय स्वास्थ्य को बनाए रखने के लिए व्यायाम महत्वपूर्ण है। प्रत्येक सप्ताह कम से कम 150 मिनट के मध्यम एरोबिक व्यायाम या 75 मिनट के जोरदार व्यायाम का लक्ष्य रखें। ⁇ 3. पर्याप्त नींद लेंः पर्याप्त गुणवत्ता वाली नींद लेना शारीरिक और मानसिक कल्याण के लिए महत्वपूर्ण है। यह मनोदशा को नियंत्रित करने, संज्ञानात्मक कार्य में सुधार करने और स्वस्थ विकास और प्रतिरक्षा कार्य का समर्थन करने में मदद करता है। हर रात 7 से 9 घंटे सोने का लक्ष्य रखें।\n",
      "\n",
      "DECODED ANSWER ONLY:\n",
      " ⁇ 1. संतुलित और पौष्टिक आहार लेंः सुनिश्चित करें कि आपके भोजन में विभिन्न प्रकार के फल और सब्जियां, दुबला प्रोटीन, साबुत अनाज और स्वस्थ वसा शामिल हों। यह आपके शरीर को सर्वोत्तम रूप से कार्य करने के लिए आवश्यक पोषक तत्व प्रदान करने में मदद करता है और पुरानी बीमारियों को रोकने में मदद कर सकता है। ⁇ 2. नियमित शारीरिक गतिविधि में संलग्न रहेंः मजबूत हड्डियों, मांसपेशियों और हृदय स्वास्थ्य को बनाए रखने के लिए व्यायाम महत्वपूर्ण है। प्रत्येक सप्ताह कम से कम 150 मिनट के मध्यम एरोबिक व्यायाम या 75 मिनट के जोरदार व्यायाम का लक्ष्य रखें। ⁇ 3. पर्याप्त नींद लेंः पर्याप्त गुणवत्ता वाली नींद लेना शारीरिक और मानसिक कल्याण के लिए महत्वपूर्ण है। यह मनोदशा को नियंत्रित करने, संज्ञानात्मक कार्य में सुधार करने और स्वस्थ विकास और प्रतिरक्षा कार्य का समर्थन करने में मदद करता है। हर रात 7 से 9 घंटे सोने का लक्ष्य रखें।\n",
      "\n",
      "BOS OK: True\n",
      "EOS OK: True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_single_sample(dataset, idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "caa8aa01-5fd6-4eb9-a682-c1e34a53c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_token_labels(dataset, idx=0):\n",
    "    sample = dataset[idx]\n",
    "    ids = sample[\"input_ids\"]\n",
    "    labels = sample[\"labels\"]\n",
    "\n",
    "    print(f\"{'TOKEN':<15} {'ID':<6} {'LABEL'}\")\n",
    "    print(\"-\"*45)\n",
    "\n",
    "    for i, l in zip(ids.tolist(), labels.tolist()):\n",
    "        tok = sp.decode([i])\n",
    "        print(f\"{tok:<15} {i:<6} {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "92b601b7-3a16-48f6-9ad9-f6729098a6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKEN           ID     LABEL\n",
      "---------------------------------------------\n",
      "                2      -100\n",
      "                28843  -100\n",
      " ⁇              1      -100\n",
      "प्रश्न          2821   -100\n",
      ":               28911  -100\n",
      " ⁇              1      -100\n",
      "स्व             1970   -100\n",
      "स्थ             357    -100\n",
      "रहने            1020   -100\n",
      "के              11     -100\n",
      "लिए             91     -100\n",
      "तीन             565    -100\n",
      "सुझाव           4535   -100\n",
      "दें             884    -100\n",
      "।               28869  -100\n",
      " ⁇              1      -100\n",
      "उत्तर           832    -100\n",
      ":               28911  -100\n",
      " ⁇              1      1\n",
      "1               28924  28924\n",
      ".               28889  28889\n",
      "संतुलित         10608  10608\n",
      "और              44     44\n",
      "पौष्टिक         13215  13215\n",
      "आहार            5479   5479\n",
      "लें             1678   1678\n",
      "ः               28920  28920\n",
      "सुनिश्चित       3010   3010\n",
      "करें            393    393\n",
      "कि              38     38\n",
      "आपके            778    778\n",
      "भोजन            2661   2661\n",
      "में             22     22\n",
      "विभिन्न         1295   1295\n",
      "प्रकार          1005   1005\n",
      "के              11     11\n",
      "फल              2347   2347\n",
      "और              44     44\n",
      "सब्जियां        11726  11726\n",
      ",               28879  28879\n",
      "दुब             6388   6388\n",
      "ला              83     83\n",
      "प्रोटीन         6769   6769\n",
      ",               28879  28879\n",
      "साबुत           23834  23834\n",
      "अनाज            6823   6823\n",
      "और              44     44\n",
      "स्वस्थ          3717   3717\n",
      "वसा             10944  10944\n",
      "शामिल           679    679\n",
      "हों             776    776\n",
      "।               28869  28869\n",
      "यह              133    133\n",
      "आपके            778    778\n",
      "शरीर            1358   1358\n",
      "को              28     28\n",
      "सर्वोत्तम       12226  12226\n",
      "रूप             377    377\n",
      "से              32     32\n",
      "कार्य           311    311\n",
      "करने            140    140\n",
      "के              11     11\n",
      "लिए             91     91\n",
      "आवश्यक          1290   1290\n",
      "पोषक            8777   8777\n",
      "तत्व            3377   3377\n",
      "प्रदान          1652   1652\n",
      "करने            140    140\n",
      "में             22     22\n",
      "मदद             981    981\n",
      "करता            629    629\n",
      "है              15     15\n",
      "और              44     44\n",
      "पुरानी          3497   3497\n",
      "बीमारियों       5155   5155\n",
      "को              28     28\n",
      "रोकने           2932   2932\n",
      "में             22     22\n",
      "मदद             981    981\n",
      "कर              36     36\n",
      "सकता            438    438\n",
      "है              15     15\n",
      "।               28869  28869\n",
      " ⁇              1      1\n",
      "2               28932  28932\n",
      ".               28889  28889\n",
      "नियमित          3420   3420\n",
      "शारीरिक         3946   3946\n",
      "गतिविधि         9069   9069\n",
      "में             22     22\n",
      "संलग्न          12531  12531\n",
      "रहें            2690   2690\n",
      "ः               28920  28920\n",
      "मजबूत           2286   2286\n",
      "हड्डियों        12737  12737\n",
      ",               28879  28879\n",
      "मांसपेशियों     11664  11664\n",
      "और              44     44\n",
      "हृदय            4727   4727\n",
      "स्वास्थ्य       1167   1167\n",
      "को              28     28\n",
      "बनाए            1566   1566\n",
      "रखने            1397   1397\n",
      "के              11     11\n",
      "लिए             91     91\n",
      "व्यायाम         8044   8044\n",
      "महत्वपूर्ण      1634   1634\n",
      "है              15     15\n",
      "।               28869  28869\n",
      "प्रत्येक        2386   2386\n",
      "सप्ताह          2296   2296\n",
      "कम              253    253\n",
      "से              32     32\n",
      "कम              253    253\n",
      "15              11776  11776\n",
      "0               28922  28922\n",
      "मिनट            1887   1887\n",
      "के              11     11\n",
      "मध्यम           6288   6288\n",
      "एरो             24342  24342\n",
      "बिक             18105  18105\n",
      "व्यायाम         8044   8044\n",
      "या              158    158\n",
      "7               9747   9747\n",
      "5               28938  28938\n",
      "मिनट            1887   1887\n",
      "के              11     11\n",
      "जोरदार          7125   7125\n",
      "व्यायाम         8044   8044\n",
      "का              40     40\n",
      "लक्ष्य          2411   2411\n",
      "रखें            2694   2694\n",
      "।               28869  28869\n",
      " ⁇              1      1\n",
      "3               28937  28937\n",
      ".               28889  28889\n",
      "पर्याप्त        3839   3839\n",
      "नींद            4499   4499\n",
      "लें             1678   1678\n",
      "ः               28920  28920\n",
      "पर्याप्त        3839   3839\n",
      "गुणवत्ता        3517   3517\n",
      "वाली            561    561\n",
      "नींद            4499   4499\n",
      "लेना            2459   2459\n",
      "शारीरिक         3946   3946\n",
      "और              44     44\n",
      "मानसिक          3754   3754\n",
      "कल्याण          2940   2940\n",
      "के              11     11\n",
      "लिए             91     91\n",
      "महत्वपूर्ण      1634   1634\n",
      "है              15     15\n",
      "।               28869  28869\n",
      "यह              133    133\n",
      "मनो             3346   3346\n",
      "दशा             12413  12413\n",
      "को              28     28\n",
      "नियंत्रित       6124   6124\n",
      "करने            140    140\n",
      ",               28879  28879\n",
      "संज्ञ           25251  25251\n",
      "ाना             221    221\n",
      "त्मक            1545   1545\n",
      "कार्य           311    311\n",
      "में             22     22\n",
      "सुधार           2064   2064\n",
      "करने            140    140\n",
      "और              44     44\n",
      "स्वस्थ          3717   3717\n",
      "विकास           777    777\n",
      "और              44     44\n",
      "प्रतिरक्षा      17259  17259\n",
      "कार्य           311    311\n",
      "का              40     40\n",
      "समर्थन          1929   1929\n",
      "करने            140    140\n",
      "में             22     22\n",
      "मदद             981    981\n",
      "करता            629    629\n",
      "है              15     15\n",
      "।               28869  28869\n",
      "हर              351    351\n",
      "रात             953    953\n",
      "7               9747   9747\n",
      "से              32     32\n",
      "9               11398  11398\n",
      "घंटे            1588   1588\n",
      "सोने            3263   3263\n",
      "का              40     40\n",
      "लक्ष्य          2411   2411\n",
      "रखें            2694   2694\n",
      "।               28869  28869\n",
      "                3      3\n"
     ]
    }
   ],
   "source": [
    "debug_token_labels(dataset, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d44f1e9a-b6ed-4eee-a7e2-ff167d5cd6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INPUT IDS: [2, 5215, 22292, 28919, 26999, 28923, 28927, 3]\n",
      "LABELS   : [-100, -100, -100, -100, -100, -100, -100, 3]\n",
      "\n",
      "DECODED FULL:\n",
      "hello world\n",
      "\n",
      "DECODED ANSWER ONLY:\n",
      "\n",
      "\n",
      "BOS OK: True\n",
      "EOS OK: True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "bad_sample = [{\"text\": \"hello world\"}]\n",
    "bad_ds = SFT_Dataset(bad_sample, sp)\n",
    "\n",
    "test_single_sample(bad_ds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae717d86-01f4-4df4-b221-6104aa418569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    seq_len = CONFIG[\"model\"][\"seq_len\"]\n",
    "    input_ids_list = []\n",
    "    labels_list = []\n",
    "    attention_mask_list = []\n",
    "\n",
    "    pad_id = CONFIG[\"data\"][\"pad_token_id\"]   # ← yahan se le\n",
    "\n",
    "    for item in batch:\n",
    "        ids = item[\"input_ids\"][:seq_len]\n",
    "        lbls = item[\"labels\"][:seq_len]\n",
    "\n",
    "        curr_len = len(ids)\n",
    "        pad_len = seq_len - curr_len\n",
    "\n",
    "        if pad_len > 0:\n",
    "            ids = torch.cat([ids, torch.full((pad_len,), pad_id, dtype=torch.long)])\n",
    "            lbls = torch.cat([lbls, torch.full((pad_len,), -100, dtype=torch.long)])\n",
    "\n",
    "        # Attention mask: 1 = real token, 0 = padding\n",
    "        mask = torch.ones(seq_len, dtype=torch.long)\n",
    "        if pad_len > 0:\n",
    "            mask[curr_len:] = 0\n",
    "\n",
    "        input_ids_list.append(ids)\n",
    "        labels_list.append(lbls)\n",
    "        attention_mask_list.append(mask)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.stack(input_ids_list),\n",
    "        \"labels\": torch.stack(labels_list),\n",
    "        \"attention_mask\": torch.stack(attention_mask_list)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4cd84d6a-1b77-4077-bf67-0b2de658e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.Size([2, 512])\n",
      "labels   : torch.Size([2, 512])\n",
      "attn_mask: torch.Size([2, 512])\n",
      "\n",
      "PAD locations:\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(\"input_ids:\", batch[\"input_ids\"].shape)\n",
    "print(\"labels   :\", batch[\"labels\"].shape)\n",
    "print(\"attn_mask:\", batch[\"attention_mask\"].shape)\n",
    "\n",
    "print(\"\\nPAD locations:\")\n",
    "print(batch[\"attention_mask\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6231a899-4780-488b-b96f-29bb40f0460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = model.cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d9c5650-57e9-4c18-8b27-6596c118cbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step done. Loss: 7.265008926391602\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "lora_params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.AdamW(lora_params,lr=2e-4, weight_decay=0.0)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "logits = model(\n",
    "    batch[\"input_ids\"].cuda(),\n",
    "    attention_mask=batch[\"attention_mask\"].cuda()\n",
    ")\n",
    "\n",
    "loss = F.cross_entropy(\n",
    "    logits.view(-1, logits.size(-1)),\n",
    "    batch[\"labels\"].cuda().view(-1),\n",
    "    ignore_index=-100\n",
    ")\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"Training step done. Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7a9063a1-35e9-436f-a317-59d4e63ac95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|█████████████████████████████████████████████████| 18177/18177 [1:25:41<00:00,  3.54it/s, loss=5.04e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 finished. Average Loss: 0.0382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|█████████████████████████████████████████████████| 18177/18177 [1:30:42<00:00,  3.34it/s, loss=2.23e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 finished. Average Loss: 0.0098\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(CONFIG[\"train\"][\"epochs\"]):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # tqdm with dataloader\n",
    "    loop = tqdm(loader, desc=f\"Epoch {epoch+1}/{CONFIG['train']['epochs']}\")\n",
    "    \n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].cuda()\n",
    "        attention_mask = batch[\"attention_mask\"].cuda()\n",
    "        labels = batch[\"labels\"].cuda()\n",
    "\n",
    "        logits = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = F.cross_entropy(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            labels.view(-1),\n",
    "            ignore_index=-100\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update tqdm postfix to show current loss\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1} finished. Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "78942589-01c0-4171-a0f5-f7478f68f580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LoRA adapter saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "save_dir = \"lora_checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "torch.save(\n",
    "    {\n",
    "        \"lora_state_dict\": {\n",
    "            k: v.cpu()\n",
    "            for k, v in model.state_dict().items()\n",
    "            if \"lora\" in k.lower()\n",
    "        },\n",
    "        \"config\": CONFIG\n",
    "    },\n",
    "    os.path.join(save_dir, \"lora_adapter.pt\")\n",
    ")\n",
    "\n",
    "print(\"✅ LoRA adapter saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0b9b0a17-b55f-427a-83ad-ef9eb589ce9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(\"lora_checkpoints/lora_adapter.pt\")\n",
    "print(len(ckpt[\"lora_state_dict\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eb612c6c-e660-46d2-a81e-63559e40e1f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'My_GPT_model' from 'decoder_only_gpt' (D:\\deep learning\\research_paper\\Transformers\\sft\\decoder_only_gpt.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdecoder_only_gpt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m My_GPT_model\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(config):\n\u001b[0;32m      3\u001b[0m     model \u001b[38;5;241m=\u001b[39m My_GPT_model(\n\u001b[0;32m      4\u001b[0m         vocab_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      5\u001b[0m         d_model\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     11\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'My_GPT_model' from 'decoder_only_gpt' (D:\\deep learning\\research_paper\\Transformers\\sft\\decoder_only_gpt.py)"
     ]
    }
   ],
   "source": [
    "from decoder_only_gpt import My_GPT_model\n",
    "def build_model(config):\n",
    "    model = My_GPT_model(\n",
    "        vocab_size=config[\"model\"][\"vocab_size\"],\n",
    "        d_model=config[\"model\"][\"d_model\"],\n",
    "        num_layers=config[\"model\"][\"n_layer\"],\n",
    "        num_heads=config[\"model\"][\"n_head\"],\n",
    "        d_ff=config[\"model\"][\"d_ff\"],\n",
    "        seq_len=config[\"model\"][\"seq_len\"],\n",
    "        dropout=config[\"model\"][\"dropout\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "46b9449b-2a66-47ee-b469-6f57d6ee4367",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'My_GPT_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[107], line 2\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(config):\n\u001b[1;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMy_GPT_model\u001b[49m(\n\u001b[0;32m      3\u001b[0m         vocab_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      4\u001b[0m         d_model\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      5\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m         num_heads\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_head\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m         d_ff\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_ff\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m         seq_len\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      9\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'My_GPT_model' is not defined"
     ]
    }
   ],
   "source": [
    "base_model = build_model(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7f790737-5c45-4ef2-aa0f-12ee5764fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"checkpoints_HindiGPT-v1_step280000.pt\", map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "674721f9-5b83-49d1-96e0-61c465a6681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = ckpt[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fe181b7d-871f-41c2-8e67-7b60d1b2568c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'optimizer', 'scaler', 'step', 'config'])\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(\"checkpoints_HindiGPT-v1_step280000.pt\", map_location=\"cpu\")\n",
    "print(ckpt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1bbfae42-f0ba-4e39-9c5a-91f40b1d8d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_orig_mod.decoder.causal_mask', '_orig_mod.decoder.embedding.weight', '_orig_mod.decoder.layers.0.swi_glu.w1.weight', '_orig_mod.decoder.layers.0.swi_glu.w2.weight', '_orig_mod.decoder.layers.0.swi_glu.w3.weight', '_orig_mod.decoder.layers.0.masked_mha.Q.weight', '_orig_mod.decoder.layers.0.masked_mha.Q.bias', '_orig_mod.decoder.layers.0.masked_mha.K.weight', '_orig_mod.decoder.layers.0.masked_mha.K.bias', '_orig_mod.decoder.layers.0.masked_mha.V.weight', '_orig_mod.decoder.layers.0.masked_mha.V.bias', '_orig_mod.decoder.layers.0.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.0.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.0.rms_norm0.weight', '_orig_mod.decoder.layers.0.rms_norm1.weight', '_orig_mod.decoder.layers.1.swi_glu.w1.weight', '_orig_mod.decoder.layers.1.swi_glu.w2.weight', '_orig_mod.decoder.layers.1.swi_glu.w3.weight', '_orig_mod.decoder.layers.1.masked_mha.Q.weight', '_orig_mod.decoder.layers.1.masked_mha.Q.bias']\n"
     ]
    }
   ],
   "source": [
    "state_dict = ckpt[\"model\"]\n",
    "print(list(state_dict.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f703743e-2d40-44aa-8c51-2912c2d10aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in checkpoint: {'decoder.layers.2.masked_mha.fc_out.weight', 'decoder.layers.4.swi_glu.w1.weight', 'decoder.layers.9.masked_mha.fc_out.weight', 'decoder.layers.5.rms_norm1.weight', 'decoder.layers.8.masked_mha.q_proj.lora_B.weight', 'decoder.layers.11.masked_mha.v_proj.lora_B.weight', 'decoder.layers.10.swi_glu.w1.weight', 'decoder.layers.6.masked_mha.v_proj.weight', 'decoder.layers.8.masked_mha.k_proj.bias', 'decoder.layers.10.masked_mha.k_base.bias', 'decoder.layers.0.masked_mha.v_base.weight', 'decoder.layers.3.masked_mha.v_proj.weight', 'decoder.layers.9.masked_mha.q_proj.bias', 'decoder.layers.4.masked_mha.v_base.bias', 'decoder.layers.11.rms_norm0.weight', 'decoder.layers.2.masked_mha.v_base.bias', 'decoder.layers.2.masked_mha.q_base.bias', 'decoder.layers.7.masked_mha.v_proj.lora_A.weight', 'decoder.layers.8.masked_mha.k_base.weight', 'decoder.layers.0.masked_mha.k_proj.bias', 'decoder.layers.1.swi_glu.w2.weight', 'decoder.layers.9.masked_mha.k_proj.bias', 'decoder.layers.3.masked_mha.k_proj.lora_B.weight', 'decoder.layers.11.masked_mha.q_proj.bias', 'decoder.layers.4.masked_mha.v_proj.bias', 'decoder.layers.3.masked_mha.q_proj.weight', 'decoder.layers.1.masked_mha.q_proj.weight', 'decoder.layers.3.masked_mha.fc_out.weight', 'decoder.layers.4.masked_mha.fc_out.weight', 'decoder.layers.5.masked_mha.q_proj.bias', 'decoder.layers.8.masked_mha.v_base.bias', 'decoder.layers.8.masked_mha.q_proj.lora_A.weight', 'decoder.layers.10.masked_mha.q_proj.lora_A.weight', 'decoder.layers.11.masked_mha.q_proj.lora_B.weight', 'decoder.layers.11.masked_mha.v_base.weight', 'decoder.layers.10.masked_mha.v_base.bias', 'decoder.layers.0.masked_mha.q_proj.lora_B.weight', 'decoder.layers.0.masked_mha.v_base.bias', 'decoder.layers.0.masked_mha.q_proj.bias', 'decoder.layers.1.rms_norm0.weight', 'decoder.causal_mask', 'decoder.layers.11.swi_glu.w2.weight', 'decoder.layers.1.masked_mha.v_base.weight', 'decoder.layers.11.masked_mha.k_proj.bias', 'decoder.layers.5.masked_mha.fc_out.weight', 'decoder.layers.10.masked_mha.k_proj.lora_B.weight', 'decoder.layers.1.swi_glu.w3.weight', 'decoder.layers.5.masked_mha.v_base.weight', 'decoder.layers.0.masked_mha.k_proj.lora_B.weight', 'decoder.layers.0.swi_glu.w2.weight', 'decoder.layers.2.masked_mha.v_proj.weight', 'decoder.layers.5.masked_mha.k_proj.bias', 'decoder.layers.7.masked_mha.v_base.weight', 'decoder.layers.8.masked_mha.k_proj.lora_A.weight', 'decoder.layers.5.masked_mha.v_base.bias', 'decoder.layers.3.masked_mha.q_base.bias', 'decoder.layers.7.masked_mha.q_base.bias', 'decoder.layers.2.masked_mha.v_proj.lora_B.weight', 'decoder.layers.8.masked_mha.q_base.bias', 'decoder.layers.8.masked_mha.fc_out.bias', 'decoder.layers.9.rms_norm0.weight', 'decoder.layers.10.masked_mha.v_base.weight', 'decoder.layers.4.masked_mha.v_base.weight', 'decoder.layers.10.masked_mha.k_proj.weight', 'decoder.layers.7.masked_mha.v_proj.lora_B.weight', 'decoder.layers.9.masked_mha.k_base.bias', 'decoder.layers.8.masked_mha.q_proj.weight', 'decoder.layers.11.masked_mha.k_proj.lora_A.weight', 'decoder.layers.10.swi_glu.w3.weight', 'decoder.layers.7.masked_mha.k_base.weight', 'decoder.layers.0.masked_mha.k_base.weight', 'decoder.layers.7.swi_glu.w3.weight', 'decoder.layers.7.masked_mha.fc_out.bias', 'decoder.layers.9.masked_mha.q_proj.lora_B.weight', 'decoder.layers.9.masked_mha.v_proj.lora_A.weight', 'lm_head.weight', 'decoder.layers.2.masked_mha.fc_out.bias', 'decoder.layers.5.masked_mha.q_proj.lora_B.weight', 'decoder.layers.8.masked_mha.k_proj.weight', 'decoder.layers.4.masked_mha.fc_out.bias', 'decoder.layers.9.masked_mha.q_base.weight', 'decoder.layers.5.rms_norm0.weight', 'decoder.layers.0.masked_mha.q_base.bias', 'decoder.layers.3.rms_norm0.weight', 'decoder.layers.6.masked_mha.q_proj.lora_B.weight', 'decoder.layers.0.masked_mha.q_base.weight', 'decoder.layers.10.masked_mha.v_proj.lora_A.weight', 'decoder.layers.3.masked_mha.k_proj.bias', 'decoder.embedding.weight', 'decoder.layers.5.swi_glu.w2.weight', 'decoder.layers.11.swi_glu.w3.weight', 'decoder.layers.6.rms_norm0.weight', 'decoder.layers.9.masked_mha.k_base.weight', 'decoder.layers.11.masked_mha.k_proj.lora_B.weight', 'decoder.layers.5.masked_mha.v_proj.lora_A.weight', 'decoder.layers.0.swi_glu.w1.weight', 'decoder.layers.3.masked_mha.q_proj.lora_A.weight', 'decoder.layers.11.masked_mha.q_proj.lora_A.weight', 'decoder.layers.1.masked_mha.q_proj.lora_B.weight', 'decoder.layers.0.masked_mha.v_proj.lora_A.weight', 'decoder.layers.0.rms_norm0.weight', 'decoder.layers.6.swi_glu.w2.weight', 'decoder.layers.7.masked_mha.v_base.bias', 'decoder.layers.2.masked_mha.v_base.weight', 'decoder.layers.4.masked_mha.q_base.weight', 'decoder.layers.7.masked_mha.v_proj.weight', 'decoder.layers.2.masked_mha.k_base.weight', 'decoder.layers.11.masked_mha.fc_out.weight', 'decoder.layers.8.rms_norm0.weight', 'decoder.layers.10.masked_mha.q_base.weight', 'decoder.layers.5.swi_glu.w3.weight', 'decoder.layers.10.masked_mha.k_base.weight', 'decoder.layers.3.masked_mha.k_base.bias', 'decoder.layers.8.swi_glu.w2.weight', 'decoder.layers.10.masked_mha.k_proj.bias', 'decoder.layers.5.masked_mha.v_proj.weight', 'decoder.layers.3.swi_glu.w2.weight', 'decoder.layers.9.masked_mha.k_proj.lora_B.weight', 'decoder.layers.9.masked_mha.v_base.weight', 'decoder.layers.1.masked_mha.v_proj.weight', 'decoder.layers.6.swi_glu.w1.weight', 'decoder.layers.8.masked_mha.v_base.weight', 'decoder.layers.10.masked_mha.q_proj.lora_B.weight', 'decoder.layers.1.masked_mha.v_proj.lora_A.weight', 'decoder.layers.9.masked_mha.k_proj.lora_A.weight', 'decoder.layers.0.masked_mha.v_proj.lora_B.weight', 'decoder.layers.2.masked_mha.q_proj.weight', 'decoder.layers.0.masked_mha.v_proj.weight', 'decoder.layers.10.masked_mha.fc_out.weight', 'decoder.layers.2.rms_norm0.weight', 'decoder.layers.2.masked_mha.q_proj.bias', 'decoder.layers.4.masked_mha.k_proj.bias', 'decoder.layers.11.masked_mha.k_proj.weight', 'decoder.layers.3.masked_mha.fc_out.bias', 'decoder.layers.5.masked_mha.k_base.weight', 'decoder.layers.2.masked_mha.k_proj.lora_A.weight', 'decoder.layers.1.swi_glu.w1.weight', 'decoder.layers.3.swi_glu.w3.weight', 'decoder.layers.6.masked_mha.v_proj.lora_A.weight', 'decoder.layers.6.masked_mha.fc_out.weight', 'decoder.layers.8.masked_mha.fc_out.weight', 'decoder.layers.3.masked_mha.q_proj.bias', 'decoder.layers.10.masked_mha.v_proj.weight', 'decoder.layers.2.masked_mha.k_base.bias', 'decoder.layers.5.masked_mha.v_proj.bias', 'decoder.layers.11.masked_mha.fc_out.bias', 'decoder.layers.3.masked_mha.v_proj.lora_B.weight', 'decoder.layers.6.masked_mha.q_proj.bias', 'decoder.layers.5.masked_mha.k_proj.lora_A.weight', 'decoder.layers.1.rms_norm1.weight', 'decoder.layers.5.masked_mha.q_proj.lora_A.weight', 'decoder.layers.1.masked_mha.k_proj.lora_A.weight', 'decoder.layers.6.masked_mha.q_base.weight', 'decoder.layers.1.masked_mha.k_base.bias', 'decoder.layers.9.masked_mha.q_proj.weight', 'decoder.layers.11.rms_norm1.weight', 'decoder.layers.7.masked_mha.q_proj.bias', 'decoder.layers.10.masked_mha.q_proj.bias', 'decoder.layers.4.masked_mha.q_proj.lora_A.weight', 'decoder.layers.7.masked_mha.k_proj.lora_B.weight', 'decoder.norm.weight', 'decoder.layers.10.masked_mha.fc_out.bias', 'decoder.layers.0.masked_mha.fc_out.bias', 'decoder.layers.1.masked_mha.k_proj.lora_B.weight', 'decoder.layers.1.masked_mha.q_base.bias', 'decoder.layers.5.masked_mha.v_proj.lora_B.weight', 'decoder.layers.3.masked_mha.q_proj.lora_B.weight', 'decoder.layers.9.masked_mha.v_proj.weight', 'decoder.layers.9.rms_norm1.weight', 'decoder.layers.9.masked_mha.q_proj.lora_A.weight', 'decoder.layers.1.masked_mha.k_base.weight', 'decoder.layers.7.masked_mha.q_base.weight', 'decoder.layers.11.masked_mha.v_proj.weight', 'decoder.layers.2.masked_mha.v_proj.lora_A.weight', 'decoder.layers.3.masked_mha.k_proj.weight', 'decoder.layers.9.masked_mha.k_proj.weight', 'decoder.layers.8.masked_mha.v_proj.weight', 'decoder.layers.10.rms_norm0.weight', 'decoder.layers.1.masked_mha.q_base.weight', 'decoder.layers.7.swi_glu.w1.weight', 'decoder.layers.1.masked_mha.v_base.bias', 'decoder.layers.7.masked_mha.k_base.bias', 'decoder.layers.8.swi_glu.w3.weight', 'decoder.layers.2.masked_mha.k_proj.bias', 'decoder.layers.8.masked_mha.q_base.weight', 'decoder.layers.11.masked_mha.q_base.weight', 'decoder.layers.4.masked_mha.q_proj.lora_B.weight', 'decoder.layers.8.swi_glu.w1.weight', 'decoder.layers.3.masked_mha.v_base.weight', 'decoder.layers.4.masked_mha.k_proj.lora_A.weight', 'decoder.layers.5.swi_glu.w1.weight', 'decoder.layers.2.masked_mha.k_proj.weight', 'decoder.layers.0.masked_mha.q_proj.weight', 'decoder.layers.8.masked_mha.k_proj.lora_B.weight', 'decoder.layers.11.masked_mha.q_proj.weight', 'decoder.layers.3.masked_mha.k_proj.lora_A.weight', 'decoder.layers.7.rms_norm0.weight', 'decoder.layers.6.masked_mha.q_base.bias', 'decoder.layers.2.masked_mha.q_proj.lora_A.weight', 'decoder.layers.8.masked_mha.v_proj.lora_A.weight', 'decoder.layers.1.masked_mha.k_proj.weight', 'decoder.layers.5.masked_mha.k_proj.weight', 'decoder.layers.6.masked_mha.fc_out.bias', 'decoder.layers.8.masked_mha.k_base.bias', 'decoder.layers.4.masked_mha.q_base.bias', 'decoder.layers.1.masked_mha.v_proj.bias', 'decoder.layers.9.masked_mha.q_base.bias', 'decoder.layers.1.masked_mha.fc_out.bias', 'decoder.layers.0.masked_mha.k_base.bias', 'decoder.layers.9.masked_mha.v_proj.bias', 'decoder.layers.3.masked_mha.v_proj.lora_A.weight', 'decoder.layers.6.masked_mha.k_proj.weight', 'decoder.layers.2.masked_mha.q_base.weight', 'decoder.layers.7.masked_mha.q_proj.lora_A.weight', 'decoder.layers.9.swi_glu.w2.weight', 'decoder.layers.9.swi_glu.w3.weight', 'decoder.layers.6.swi_glu.w3.weight', 'decoder.layers.9.masked_mha.v_proj.lora_B.weight', 'decoder.layers.8.masked_mha.v_proj.lora_B.weight', 'decoder.layers.11.masked_mha.v_proj.lora_A.weight', 'decoder.layers.5.masked_mha.k_base.bias', 'decoder.layers.2.masked_mha.v_proj.bias', 'decoder.layers.5.masked_mha.q_base.weight', 'decoder.layers.0.masked_mha.v_proj.bias', 'decoder.layers.4.masked_mha.k_proj.weight', 'decoder.layers.3.swi_glu.w1.weight', 'decoder.layers.0.swi_glu.w3.weight', 'decoder.layers.4.swi_glu.w2.weight', 'decoder.layers.5.masked_mha.fc_out.bias', 'decoder.layers.11.masked_mha.q_base.bias', 'decoder.layers.6.masked_mha.q_proj.weight', 'decoder.layers.7.masked_mha.k_proj.lora_A.weight', 'decoder.layers.0.masked_mha.q_proj.lora_A.weight', 'decoder.layers.7.masked_mha.v_proj.bias', 'decoder.layers.4.masked_mha.q_proj.weight', 'decoder.layers.9.masked_mha.fc_out.bias', 'decoder.layers.10.masked_mha.v_proj.lora_B.weight', 'decoder.layers.11.masked_mha.k_base.weight', 'decoder.layers.0.masked_mha.k_proj.weight', 'decoder.layers.1.masked_mha.q_proj.bias', 'decoder.layers.2.rms_norm1.weight', 'decoder.layers.1.masked_mha.k_proj.bias', 'decoder.layers.7.rms_norm1.weight', 'decoder.layers.2.swi_glu.w1.weight', 'decoder.layers.4.masked_mha.k_base.weight', 'decoder.layers.8.rms_norm1.weight', 'decoder.layers.2.masked_mha.k_proj.lora_B.weight', 'decoder.layers.9.swi_glu.w1.weight', 'decoder.layers.10.swi_glu.w2.weight', 'decoder.layers.4.masked_mha.v_proj.lora_B.weight', 'decoder.layers.2.masked_mha.q_proj.lora_B.weight', 'decoder.layers.4.swi_glu.w3.weight', 'decoder.layers.5.masked_mha.k_proj.lora_B.weight', 'decoder.layers.6.masked_mha.k_proj.lora_A.weight', 'decoder.layers.11.swi_glu.w1.weight', 'decoder.layers.4.masked_mha.v_proj.weight', 'decoder.layers.7.masked_mha.q_proj.lora_B.weight', 'decoder.layers.6.masked_mha.k_proj.bias', 'decoder.layers.3.masked_mha.k_base.weight', 'decoder.layers.3.masked_mha.v_proj.bias', 'decoder.layers.4.masked_mha.q_proj.bias', 'decoder.layers.11.masked_mha.v_base.bias', 'decoder.layers.7.masked_mha.k_proj.bias', 'decoder.layers.3.masked_mha.q_base.weight', 'decoder.layers.9.masked_mha.v_base.bias', 'decoder.layers.7.masked_mha.k_proj.weight', 'decoder.layers.2.swi_glu.w3.weight', 'decoder.layers.10.masked_mha.q_proj.weight', 'decoder.layers.11.masked_mha.v_proj.bias', 'decoder.layers.6.masked_mha.v_proj.lora_B.weight', 'decoder.layers.4.rms_norm0.weight', 'decoder.layers.10.masked_mha.k_proj.lora_A.weight', 'decoder.layers.10.masked_mha.v_proj.bias', 'decoder.layers.11.masked_mha.k_base.bias', 'decoder.layers.8.masked_mha.v_proj.bias', 'decoder.layers.8.masked_mha.q_proj.bias', 'decoder.layers.4.masked_mha.k_base.bias', 'decoder.layers.0.masked_mha.k_proj.lora_A.weight', 'decoder.layers.3.rms_norm1.weight', 'decoder.layers.1.masked_mha.v_proj.lora_B.weight', 'decoder.layers.5.masked_mha.q_proj.weight', 'decoder.layers.6.masked_mha.k_base.bias', 'decoder.layers.6.masked_mha.v_base.bias', 'decoder.layers.6.masked_mha.v_proj.bias', 'decoder.layers.0.rms_norm1.weight', 'decoder.layers.10.rms_norm1.weight', 'decoder.layers.4.masked_mha.k_proj.lora_B.weight', 'decoder.layers.10.masked_mha.q_base.bias', 'decoder.layers.6.masked_mha.k_base.weight', 'decoder.layers.2.swi_glu.w2.weight', 'decoder.layers.4.masked_mha.v_proj.lora_A.weight', 'decoder.layers.6.masked_mha.q_proj.lora_A.weight', 'decoder.layers.0.masked_mha.fc_out.weight', 'decoder.layers.3.masked_mha.v_base.bias', 'decoder.layers.4.rms_norm1.weight', 'decoder.layers.6.masked_mha.v_base.weight', 'decoder.layers.6.rms_norm1.weight', 'decoder.layers.7.masked_mha.fc_out.weight', 'decoder.layers.6.masked_mha.k_proj.lora_B.weight', 'decoder.layers.7.swi_glu.w2.weight', 'decoder.layers.1.masked_mha.fc_out.weight', 'decoder.layers.5.masked_mha.q_base.bias', 'decoder.layers.1.masked_mha.q_proj.lora_A.weight', 'decoder.layers.7.masked_mha.q_proj.weight'}\n",
      "Extra in checkpoint: {'_orig_mod.decoder.layers.8.masked_mha.V.bias', '_orig_mod.decoder.layers.8.masked_mha.V.weight', '_orig_mod.decoder.layers.0.masked_mha.K.bias', '_orig_mod.decoder.layers.11.swi_glu.w2.weight', '_orig_mod.decoder.layers.1.masked_mha.Q.weight', '_orig_mod.decoder.layers.2.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.9.swi_glu.w3.weight', '_orig_mod.decoder.layers.9.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.6.rms_norm0.weight', '_orig_mod.decoder.layers.8.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.4.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.7.masked_mha.K.weight', '_orig_mod.decoder.layers.0.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.7.swi_glu.w1.weight', '_orig_mod.decoder.layers.7.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.6.masked_mha.Q.bias', '_orig_mod.decoder.causal_mask', '_orig_mod.decoder.layers.9.masked_mha.V.weight', '_orig_mod.decoder.layers.9.swi_glu.w2.weight', '_orig_mod.decoder.layers.2.swi_glu.w2.weight', '_orig_mod.decoder.layers.5.swi_glu.w3.weight', '_orig_mod.decoder.layers.10.masked_mha.Q.bias', '_orig_mod.decoder.layers.0.masked_mha.V.bias', '_orig_mod.decoder.layers.4.masked_mha.K.bias', '_orig_mod.decoder.layers.6.masked_mha.K.weight', '_orig_mod.decoder.layers.1.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.6.swi_glu.w2.weight', '_orig_mod.decoder.layers.11.swi_glu.w3.weight', '_orig_mod.decoder.layers.11.masked_mha.V.weight', '_orig_mod.decoder.layers.11.rms_norm0.weight', '_orig_mod.decoder.layers.0.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.11.masked_mha.Q.bias', '_orig_mod.decoder.layers.11.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.10.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.2.masked_mha.V.weight', '_orig_mod.decoder.layers.5.swi_glu.w1.weight', '_orig_mod.decoder.layers.1.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.3.swi_glu.w2.weight', '_orig_mod.decoder.layers.8.rms_norm1.weight', '_orig_mod.decoder.layers.7.masked_mha.Q.weight', '_orig_mod.decoder.layers.3.masked_mha.Q.weight', '_orig_mod.decoder.layers.7.masked_mha.V.bias', '_orig_mod.decoder.layers.6.swi_glu.w3.weight', '_orig_mod.decoder.layers.7.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.9.rms_norm0.weight', '_orig_mod.decoder.layers.11.masked_mha.K.bias', '_orig_mod.decoder.layers.3.swi_glu.w3.weight', '_orig_mod.decoder.layers.8.masked_mha.K.bias', '_orig_mod.decoder.layers.5.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.9.swi_glu.w1.weight', '_orig_mod.decoder.layers.9.masked_mha.K.bias', '_orig_mod.decoder.layers.3.swi_glu.w1.weight', '_orig_mod.decoder.layers.0.swi_glu.w3.weight', '_orig_mod.decoder.layers.1.masked_mha.Q.bias', '_orig_mod.decoder.layers.4.masked_mha.Q.bias', '_orig_mod.decoder.embedding.weight', '_orig_mod.decoder.layers.0.masked_mha.V.weight', '_orig_mod.decoder.layers.1.masked_mha.K.weight', '_orig_mod.decoder.layers.3.masked_mha.V.weight', '_orig_mod.decoder.layers.2.masked_mha.Q.weight', '_orig_mod.decoder.layers.4.rms_norm1.weight', '_orig_mod.decoder.layers.5.masked_mha.Q.weight', '_orig_mod.decoder.layers.1.swi_glu.w2.weight', '_orig_mod.decoder.layers.10.swi_glu.w3.weight', '_orig_mod.decoder.layers.11.masked_mha.Q.weight', '_orig_mod.decoder.layers.11.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.1.masked_mha.V.weight', '_orig_mod.decoder.layers.8.masked_mha.Q.weight', '_orig_mod.decoder.layers.5.masked_mha.K.weight', '_orig_mod.decoder.layers.3.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.4.masked_mha.V.bias', '_orig_mod.decoder.layers.3.masked_mha.Q.bias', '_orig_mod.decoder.layers.5.masked_mha.V.bias', '_orig_mod.decoder.layers.7.swi_glu.w2.weight', '_orig_mod.decoder.layers.9.masked_mha.K.weight', '_orig_mod.decoder.layers.1.masked_mha.V.bias', '_orig_mod.decoder.norm.weight', '_orig_mod.decoder.layers.4.swi_glu.w2.weight', '_orig_mod.decoder.layers.6.masked_mha.Q.weight', '_orig_mod.decoder.layers.7.masked_mha.V.weight', '_orig_mod.decoder.layers.7.rms_norm0.weight', '_orig_mod.decoder.layers.1.rms_norm1.weight', '_orig_mod.decoder.layers.4.masked_mha.Q.weight', '_orig_mod.decoder.layers.9.masked_mha.Q.bias', '_orig_mod.decoder.layers.7.rms_norm1.weight', '_orig_mod.decoder.layers.1.masked_mha.K.bias', '_orig_mod.decoder.layers.11.rms_norm1.weight', '_orig_mod.decoder.layers.8.masked_mha.K.weight', '_orig_mod.decoder.layers.3.masked_mha.V.bias', '_orig_mod.decoder.layers.0.rms_norm1.weight', '_orig_mod.decoder.layers.7.swi_glu.w3.weight', '_orig_mod.decoder.layers.4.rms_norm0.weight', '_orig_mod.decoder.layers.10.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.11.masked_mha.V.bias', '_orig_mod.decoder.layers.3.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.9.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.0.masked_mha.Q.weight', '_orig_mod.decoder.layers.0.rms_norm0.weight', '_orig_mod.decoder.layers.5.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.6.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.8.swi_glu.w3.weight', '_orig_mod.decoder.layers.5.masked_mha.K.bias', '_orig_mod.decoder.layers.10.swi_glu.w2.weight', '_orig_mod.decoder.layers.5.swi_glu.w2.weight', '_orig_mod.decoder.layers.10.swi_glu.w1.weight', '_orig_mod.decoder.layers.5.masked_mha.Q.bias', '_orig_mod.decoder.layers.8.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.8.swi_glu.w1.weight', '_orig_mod.decoder.layers.2.masked_mha.K.bias', '_orig_mod.decoder.layers.9.masked_mha.Q.weight', '_orig_mod.decoder.layers.10.masked_mha.V.bias', '_orig_mod.decoder.layers.7.masked_mha.Q.bias', '_orig_mod.decoder.layers.10.rms_norm0.weight', '_orig_mod.decoder.layers.6.rms_norm1.weight', '_orig_mod.decoder.layers.4.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.2.masked_mha.K.weight', '_orig_mod.decoder.layers.11.swi_glu.w1.weight', '_orig_mod.decoder.layers.1.swi_glu.w3.weight', '_orig_mod.decoder.layers.4.swi_glu.w1.weight', '_orig_mod.decoder.layers.8.swi_glu.w2.weight', '_orig_mod.decoder.layers.1.swi_glu.w1.weight', '_orig_mod.decoder.layers.8.rms_norm0.weight', '_orig_mod.decoder.layers.10.rms_norm1.weight', '_orig_mod.lm_head.weight', '_orig_mod.decoder.layers.3.masked_mha.K.weight', '_orig_mod.decoder.layers.2.swi_glu.w3.weight', '_orig_mod.decoder.layers.10.masked_mha.V.weight', '_orig_mod.decoder.layers.6.masked_mha.K.bias', '_orig_mod.decoder.layers.3.masked_mha.K.bias', '_orig_mod.decoder.layers.5.masked_mha.V.weight', '_orig_mod.decoder.layers.0.swi_glu.w2.weight', '_orig_mod.decoder.layers.2.swi_glu.w1.weight', '_orig_mod.decoder.layers.2.masked_mha.fc_out.bias', '_orig_mod.decoder.layers.6.masked_mha.fc_out.weight', '_orig_mod.decoder.layers.3.rms_norm0.weight', '_orig_mod.decoder.layers.10.masked_mha.Q.weight', '_orig_mod.decoder.layers.4.masked_mha.V.weight', '_orig_mod.decoder.layers.8.masked_mha.Q.bias', '_orig_mod.decoder.layers.6.masked_mha.V.bias', '_orig_mod.decoder.layers.2.rms_norm0.weight', '_orig_mod.decoder.layers.3.rms_norm1.weight', '_orig_mod.decoder.layers.9.masked_mha.V.bias', '_orig_mod.decoder.layers.7.masked_mha.K.bias', '_orig_mod.decoder.layers.10.masked_mha.K.bias', '_orig_mod.decoder.layers.0.swi_glu.w1.weight', '_orig_mod.decoder.layers.5.rms_norm1.weight', '_orig_mod.decoder.layers.4.masked_mha.K.weight', '_orig_mod.decoder.layers.6.swi_glu.w1.weight', '_orig_mod.decoder.layers.2.masked_mha.V.bias', '_orig_mod.decoder.layers.2.masked_mha.Q.bias', '_orig_mod.decoder.layers.11.masked_mha.K.weight', '_orig_mod.decoder.layers.1.rms_norm0.weight', '_orig_mod.decoder.layers.2.rms_norm1.weight', '_orig_mod.decoder.layers.9.rms_norm1.weight', '_orig_mod.decoder.layers.10.masked_mha.K.weight', '_orig_mod.decoder.layers.0.masked_mha.K.weight', '_orig_mod.decoder.layers.6.masked_mha.V.weight', '_orig_mod.decoder.layers.0.masked_mha.Q.bias', '_orig_mod.decoder.layers.4.swi_glu.w3.weight', '_orig_mod.decoder.layers.5.rms_norm0.weight'}\n"
     ]
    }
   ],
   "source": [
    "model_keys = set(base_model.state_dict().keys())\n",
    "ckpt_keys  = set(state_dict.keys())\n",
    "\n",
    "print(\"Missing in checkpoint:\", model_keys - ckpt_keys)\n",
    "print(\"Extra in checkpoint:\", ckpt_keys - model_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "34c3233b-7e09-4016-8cae-dac1149e0b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_state = ckpt[\"model\"]\n",
    "\n",
    "clean_state = {}\n",
    "for k, v in raw_state.items():\n",
    "    if k.startswith(\"_orig_mod.\"):\n",
    "        k = k.replace(\"_orig_mod.\", \"\")\n",
    "    clean_state[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75f44011-1fa8-41d0-ae6c-9ed2b8bd9b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['decoder.causal_mask', 'decoder.embedding.weight', 'decoder.layers.0.swi_glu.w1.weight', 'decoder.layers.0.swi_glu.w2.weight', 'decoder.layers.0.swi_glu.w3.weight', 'decoder.layers.0.masked_mha.Q.weight', 'decoder.layers.0.masked_mha.Q.bias', 'decoder.layers.0.masked_mha.K.weight', 'decoder.layers.0.masked_mha.K.bias', 'decoder.layers.0.masked_mha.V.weight', 'decoder.layers.0.masked_mha.V.bias', 'decoder.layers.0.masked_mha.fc_out.weight', 'decoder.layers.0.masked_mha.fc_out.bias', 'decoder.layers.0.rms_norm0.weight', 'decoder.layers.0.rms_norm1.weight', 'decoder.layers.1.swi_glu.w1.weight', 'decoder.layers.1.swi_glu.w2.weight', 'decoder.layers.1.swi_glu.w3.weight', 'decoder.layers.1.masked_mha.Q.weight', 'decoder.layers.1.masked_mha.Q.bias']\n"
     ]
    }
   ],
   "source": [
    "state_dict = ckpt[\"model\"]\n",
    "print(list(clean_state.keys())[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9969a424-7a26-4e25-94e3-25f8dc077569",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'My_GPT_model' from 'decoder_only_gpt' (D:\\deep learning\\research_paper\\Transformers\\sft\\decoder_only_gpt.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdecoder_only_gpt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m My_GPT_model\n\u001b[0;32m      2\u001b[0m base_model \u001b[38;5;241m=\u001b[39m My_GPT_model(vocab_size\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      3\u001b[0m         d_model\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      4\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m         seq_len\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      8\u001b[0m         dropout\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      9\u001b[0m base_model\u001b[38;5;241m.\u001b[39mload_state_dict(clean_state, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'My_GPT_model' from 'decoder_only_gpt' (D:\\deep learning\\research_paper\\Transformers\\sft\\decoder_only_gpt.py)"
     ]
    }
   ],
   "source": [
    "from decoder_only_gpt import My_GPT_model\n",
    "base_model = My_GPT_model(vocab_size=CONFIG[\"model\"][\"vocab_size\"],\n",
    "        d_model=CONFIG[\"model\"][\"d_model\"],\n",
    "        num_layers=CONFIG[\"model\"][\"n_layer\"],\n",
    "        num_heads=CONFIG[\"model\"][\"n_head\"],\n",
    "        d_ff=CONFIG[\"model\"][\"d_ff\"],\n",
    "        seq_len=CONFIG[\"model\"][\"seq_len\"],\n",
    "        dropout=CONFIG[\"model\"][\"dropout\"])\n",
    "base_model.load_state_dict(clean_state, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66975d-5cc8-4249-9c8b-9111345a0dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
